#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
taint_ip_merged_fin_memory_intergration_ing.py
ì¸í„°í”„ë¡œì‹œì €(ìµœëŒ€ 10í™‰) + dyn_methods + callerâ†’callee ì¸ìê°’ ì „íŒŒ + íŒŒë¼ë¯¸í„° origin ì „íŒŒ
[PATCH: external-like ë©”ì„œë“œë„ ì‹¤ì œ ì½”ë“œê°€ ìˆìœ¼ë©´ ë“¤ì–´ê°€ë„ë¡ ìˆ˜ì •í•œ ë²„ì „]
[PATCH2: StringBuilder ì—°ì‚° ì¶”ì ]
[PATCH3: íŒŒë¼ë¯¸í„° ì—†ëŠ” File ë¦¬í„´ ë©”ì„œë“œë„, this(0ë²ˆ)ìœ¼ë¡œ ë„˜ì–´ì˜¨ ë””ë ‰í„°ë¦¬/ì´ë¦„ì„ ì¼ë°˜ ê·œì¹™ìœ¼ë¡œ ë³µì›]
[PATCH4: ë²”ìš© ë² ì´ìŠ¤ ë””ë ‰í„°ë¦¬ ê·œì¹™ í…Œì´ë¸”(BASE_DIR_RULES) + JOIN íŒ¨í„´ í™•ì¥ + DIR_LIKE íŒ¨í„´ í™•ì¥]
[PATCH5: return summary ë„ì… â€” callee ë‚´ë¶€ì—ì„œ File(base,"literal")ì„ ë§Œë“¤ì–´ return í•˜ëŠ” ì»¤ìŠ¤í…€ getter ì¶”ì ]
[PATCH-CTOR_BIND: track_with_interproc ë‚´ ìƒì„±ì(<init>) í˜¸ì¶œ ì‹œ this ê°ì²´ì— ctor_arg* ë°”ì¸ë”© + param_bindings ì¦‰ì‹œ ì£¼ì…]
[PATCH-FIX-SUMMARY-MATCH: scan_return_file_from_base_literal ë‚´ë¶€ ì‹œê·¸ë‹ˆì²˜ ë¹„êµë¥¼ ëª¨ë‘ norm_sig() ì •ê·œí™”ë¡œ í†µì¼ â€” ëŒ€ì†Œë¬¸ì/ê³µë°± ë¶ˆì¼ì¹˜ ë²„ê·¸ ìˆ˜ì •]
[PATCH-FIX callee_n order + pending_invoke 5-tuple standardize + trace_invoke logging]
[PATCH-DS-WRAPPER: DataStore ë˜í¼(safePreferencesDataStore ë“±) ì¸ì‹ ë° trace_slice note íƒœê¹…]
[PATCH-RE-TRANSMISSION: íŒŒë¼ë¯¸í„° ì¬ì „íŒŒ ë¡œì§ í†µí•©]
[PATCH-MEMORY-OPTIMIZE: JSONL ìŠ¤íŠ¸ë¦¬ë° ì €ì¥ + ê±°ëŒ€ ë©”ì„œë“œ í•„í„°(300+ inst) + ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ë¡œê·¸(100ê°œë§ˆë‹¤) + StringBuilder í¬ê¸° ì œí•œ(2048ì)]
[PATCH-META-STORAGE-AUTO: LX/191 Storage Config ìë™ ì¸ì‹ + sparse-switch/if-else íŒŒì‹± + meta_storage_ids.json ìƒì„±]
[PATCH-ANDROIDMANIFEST: ë©€í‹° í”„ë¡œì„¸ìŠ¤ ìë™ ê°ì§€(service/provider/receiver/activity) + Crashlytics v2 ì „ í”„ë¡œì„¸ìŠ¤ í™•ì¥]
"""

import argparse, json, re, psutil, os
import sys
from collections import defaultdict
from typing import Dict, Any, List, Optional, Tuple, Set
from datetime import datetime
from pathlib import Path

os.environ['PYTHONIOENCODING'] = 'utf-8'

if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Context + int + File ë°˜í™˜ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ íŒ¨í„´ (ì¡°ê¸ˆ ë„“ê²Œ)
META_STORAGE_SIG_RE = re.compile(
    r"^LX/[^;]+;->[A-Z][0-9]+\(Landroid/content/Context;I\)Ljava/io/File;$"
    r"^LX/[^;]+;->A0[0-9]\("  # A00~A09 ë©”ì„œë“œëª…
    r"Landroid/content/Context;"  # ì²« ë²ˆì§¸ ì¸ìëŠ” Context
    r"[^)]*"  # ë‚˜ë¨¸ì§€ ì¸ìëŠ” ë­ë“  OK (I, IZ, Z ë“±)
    r"\)"
    r"(?:Ljava/io/File;|Ljava/lang/String;)$"  # File ë˜ëŠ” String ë°˜í™˜
)

def _looks_like_dir_name(s: str) -> bool:
    """
    storage_id_subdir.txt ê¸°ì¤€ìœ¼ë¡œ:
    - ê³µë°±ì´ ì—†ê³ 
    - ë„ˆë¬´ ê¸´ ë¬¸ì¥ ì•„ë‹ˆê³ 
    - ì—ëŸ¬ ë©”ì‹œì§€/ë¡œê·¸ ë¬¸ì¥ì²˜ëŸ¼ ë³´ì´ëŠ”ê±´ ë²„ë¦¼
    - ìŠ¬ë˜ì‹œ(/)ë‚˜ ì–¸ë”ìŠ¤ì½”ì–´, ì•ŒíŒŒë²³/ìˆ«ì ì¡°í•© ì •ë„ë§Œ í—ˆìš©
    """
    if not s:
        return False
    s = s.strip()

    # ÑĞ²í•œ ì—ëŸ¬/ë¡œê·¸ ë¬¸ì¥ ì»·
    if "unable to" in s.lower():
        return False
    if "failed" in s.lower():
        return False
    if "exception" in s.lower():
        return False

    # ê³µë°± ë“¤ì–´ê°€ë©´ ë””ë ‰í„°ë¦¬ ì´ë¦„ìœ¼ë¡œ ë³´ê¸° í˜ë“¦
    if " " in s:
        return False

    # ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ì¼ ê°€ëŠ¥ì„± â†‘
    if len(s) > 64:
        return False

    # ë””ë ‰í„°ë¦¬ ì´ë¦„ì— ìì£¼ ë‚˜ì˜¤ëŠ” ë¬¸ìë§Œ í—ˆìš©
    for ch in s:
        if ch.isalnum():
            continue
        if ch in "._-/":
            continue
        # ê·¸ ì™¸ íŠ¹ìˆ˜ë¬¸ì ì„ì—¬ ìˆìœ¼ë©´ ì¼ë‹¨ ë²„ë¦¼
        return False

    return True

def _parse_sparse_switch_table(instructions: list, switch_label: str) -> Dict[int, str]:
    """
    sparse-switch í…Œì´ë¸” íŒŒì‹±
    
    ì˜ˆì‹œ:
    :sswitch_data_0
    .sparse-switch
        0xc9 -> :sswitch_0  # case 201
        0xca -> :sswitch_1  # case 202
    .end sparse-switch
    
    Returns:
        {201: ":sswitch_0", 202: ":sswitch_1", ...}
    """
    in_table = False
    switch_map = {}
    
    for ins in instructions:
        line = ins.get_output()
        
        # í…Œì´ë¸” ì‹œì‘ ê°ì§€
        if switch_label in line and ".sparse-switch" in line:
            in_table = True
            continue
        
        # í…Œì´ë¸” ë
        if in_table and ".end sparse-switch" in line:
            break
        
        # í…Œì´ë¸” ì—”íŠ¸ë¦¬ íŒŒì‹±: "0xc9 -> :sswitch_0"
        if in_table:
            match = re.match(r'\s*(0x[0-9a-fA-F]+|-?[0-9]+)\s*->\s*(:sswitch_\d+)', line)
            if match:
                val_str, label = match.groups()
                try:
                    val = int(val_str, 16) if val_str.startswith("0x") else int(val_str)
                    switch_map[val] = label
                except:
                    pass
    
    return switch_map


def _find_label_position(instructions: list, label: str) -> Optional[int]:
    """ë ˆì´ë¸”ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°"""
    for i, ins in enumerate(instructions):
        if label in ins.get_output():
            return i
    return None


def _extract_from_case_block(instructions: list, start_idx: int, end_labels: Set[str]) -> Optional[Tuple[str, str]]:
    """
    case ë¸”ë¡ì—ì„œ (dir_name, base_type) ì¶”ì¶œ
    
    Args:
        instructions: ì „ì²´ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ë¦¬ìŠ¤íŠ¸
        start_idx: case ë ˆì´ë¸” ì‹œì‘ ì¸ë±ìŠ¤
        end_labels: ë‹¤ìŒ case ë ˆì´ë¸”ë“¤ (ì—¬ê¸°ê¹Œì§€ë§Œ ë¶„ì„)
    
    Returns:
        ("lib-compressed", "files") or None
    """
    dir_name = None
    base_type = None  # "files", "cache", or None
    
    # case ë¸”ë¡ì€ ë³´í†µ 50ì¤„ ì´ë‚´
    for i in range(start_idx, min(start_idx + 50, len(instructions))):
        ins = instructions[i]
        line = ins.get_output()
        op = ins.get_name()
        
        # ë‹¤ìŒ case ë ˆì´ë¸” ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
        if any(label in line for label in end_labels):
            break
        
        # return ë§Œë‚˜ë©´ ì¤‘ë‹¨
        if op.startswith("return"):
            break
        
        # const-stringìœ¼ë¡œ ë””ë ‰í„°ë¦¬ ì´ë¦„ ì°¾ê¸°
        if op == "const-string":
            match = re.match(r'v\d+,\s*"([^"]+)"', line)
            if match:
                candidate = match.group(1)
                if _looks_like_dir_name(candidate):
                    dir_name = candidate
        
        # ë² ì´ìŠ¤ ë””ë ‰í„°ë¦¬ íƒ€ì… ê°ì§€
        if "getFilesDir" in line:
            base_type = "files"
        elif "getCacheDir" in line:
            base_type = "cache"
        elif "getExternalFilesDir" in line:
            base_type = "external_files"
    
    if dir_name:
        return (dir_name, base_type or "unknown")
    return None


def extract_from_sparse_switch(method) -> Dict[int, str]:
    """
    sparse-switch í…Œì´ë¸”ì—ì„œ storage_id â†’ subdir ë§¤í•‘ ì¶”ì¶œ
    
    Args:
        method: EncodedMethod ê°ì²´
    
    Returns:
        {114712842: 'files/mqtt_analytics', ...}
    """
    try:
        code = method.get_code()
        bc = code.get_bc()
        insns = list(bc.get_instructions())
        insns_text = "\n".join(ins.get_output() for ins in insns)
    except Exception:
        return {}
    
    # Step 1: sparse-switch í…Œì´ë¸” íŒŒì‹±
    switch_data = _parse_sparse_switch_table(insns, ":sswitch_data_0")
    if not switch_data:
        print("  âŒ sparse-switch í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨")
        return {}
    
    print(f"  âœ“ {len(switch_data)}ê°œ case ë°œê²¬")
    
    # Step 2: ê° case ë¸”ë¡ì—ì„œ ë””ë ‰í„°ë¦¬ ì´ë¦„ ì¶”ì¶œ
    mapping = {}
    all_labels = set(switch_data.values())
    
    for storage_id, label in switch_data.items():
        label_idx = _find_label_position(insns, label)
        if label_idx is None:
            continue
        
        result = _extract_from_case_block(insns, label_idx, all_labels)
        if result:
            dir_name, base_type = result
            # base_typeì— ë”°ë¼ ì „ì²´ ê²½ë¡œ ìƒì„±
            if base_type == "cache":
                full_path = f"cache/{dir_name}"
            elif base_type == "external_files":
                full_path = f"external_files/{dir_name}"
            else:  # files ë˜ëŠ” unknown
                full_path = f"files/{dir_name}"
            
            mapping[storage_id] = full_path
    
    return mapping


def find_storage_method_in_class(dx, target_class: str):
    """
    íŠ¹ì • í´ë˜ìŠ¤ì—ì„œ Storage Config ë©”ì„œë“œ ì°¾ê¸°
    
    Returns:
        EncodedMethod or None
    """
    for ma in dx.get_methods():
        try:
            em = ma.get_method()
            if em.get_class_name() == target_class:
                desc = em.get_descriptor()
                if META_STORAGE_SIG_RE.match(desc):
                    code = em.get_code()
                    if code:
                        return em
        except Exception:
            continue
    return None


# ========== Meta Storage ë²”ìš© ì¶”ì¶œ ì—”ì§„ ==========
def _parse_sparse_switch_unified(payload_ins) -> List[int]:
    """
    sparse-switch-payload instructionì—ì„œ storage ID ëª©ë¡ ì¶”ì¶œ
    
    Args:
        payload_ins: sparse-switch-payload instruction ê°ì²´
        
    Returns:
        storage_id ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ)
        ì˜ˆ: [0x6d6610a, 0x969066d, 0xb92ec5a, ...]
    """
    try:
        # âœ… ìˆ˜ì •: get_name()ìœ¼ë¡œ instruction íƒ€ì… í™•ì¸
        ins_name = payload_ins.get_name()
        print(f"[PARSE] Instruction name: {ins_name}")
        
        if "sparse-switch-payload" not in ins_name:
            print(f"[PARSE] âœ— ì˜¬ë°”ë¥¸ payload instructionì´ ì•„ë‹˜ (name: {ins_name})")
            return []
        
        # âœ… ìˆ˜ì •: get_output()ì—ì„œ 16ì§„ìˆ˜ ê°’ë§Œ ì¶”ì¶œ
        output = payload_ins.get_output().strip()
        print(f"[PARSE] Payload output: {output}")
        
        # "6d6610a 969066d ..." í˜•ì‹ì—ì„œ 16ì§„ìˆ˜ ì¶”ì¶œ
        parts = output.split()
        
        if not parts:
            print(f"[PARSE] âœ— payloadì— ë°ì´í„° ì—†ìŒ")
            return []
        
        # ëª¨ë“  ë¶€ë¶„ì„ 16ì§„ìˆ˜ë¡œ íŒŒì‹±
        storage_ids = []
        for part in parts:
            try:
                # 16ì§„ìˆ˜ ê°’ íŒŒì‹±
                val = int(part, 16)
                storage_ids.append(val)
            except ValueError:
                # íŒŒì‹± ì‹¤íŒ¨í•œ ê°’ì€ ê±´ë„ˆëœ€ (ì˜ˆ: "sparse-switch-payload" ê°™ì€ í…ìŠ¤íŠ¸)
                continue
        
        print(f"[PARSE] âœ“ {len(storage_ids)}ê°œ storage ID ì¶”ì¶œ")
        for i, sid in enumerate(storage_ids[:5]):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"[PARSE]   [{i}] {sid:#x}")
        if len(storage_ids) > 5:
            print(f"[PARSE]   ... (+{len(storage_ids)-5}ê°œ ë”)")
        
        return storage_ids
        
    except Exception as e:
        print(f"[PARSE] âœ— ì˜ˆì™¸ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return []


def _extract_dir_from_case_block(instructions: list, start_idx: int) -> Optional[str]:
    """
    case ë¸”ë¡ì—ì„œ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ì¶”ì¶œ
    
    íŒ¨í„´:
    1. const-string v2, "app_analytics"
    2. getCacheDir() / getFilesDir()
    3. goto
    
    Returns:
        "cache/app_analytics" or "files/lib-compressed" or None
    """
    dir_name = None
    base_type = None  # âœ… ìˆ˜ì •: ê¸°ë³¸ê°’ Noneìœ¼ë¡œ ë³€ê²½
    
    # âœ… ìˆ˜ì •: ë²”ìœ„ í™•ì¥ (10 â†’ 15)
    for i in range(start_idx, min(start_idx + 15, len(instructions))):
        ins = instructions[i]
        line = ins.get_output()
        op = ins.get_name()
        
        # return ë§Œë‚˜ë©´ ì¢…ë£Œ
        if op.startswith("return"):
            break
        
        # goto ë§Œë‚˜ë©´ ì¢…ë£Œ (ë‹¤ìŒ caseë¡œ ì´ë™)
        if op.startswith("goto"):
            break
        
        # const-stringìœ¼ë¡œ ë””ë ‰í„°ë¦¬ ì´ë¦„ ì°¾ê¸°
        if "const-string" in op:
            # âœ… ìˆ˜ì •: ì •ê·œì‹ ìˆœì„œ ë³€ê²½ (í°ë”°ì˜´í‘œ ìš°ì„ )
            match = re.search(r'"([^"]+)"', line)
            if not match:
                match = re.search(r"'([^']+)'", line)
            
            if match:
                candidate = match.group(1)
                # ë””ë ‰í„°ë¦¬ ì´ë¦„ ê²€ì¦
                if candidate and len(candidate) < 64 and " " not in candidate:
                    # âœ… ì¶”ê°€: ì—ëŸ¬ ë©”ì‹œì§€ í•„í„°ë§
                    if "Storage config" not in candidate and "not in startup" not in candidate:
                        dir_name = candidate
        
        # ë² ì´ìŠ¤ ë””ë ‰í„°ë¦¬ íƒ€ì… ê°ì§€
        if "getCacheDir" in line:
            base_type = "cache"
        elif "getFilesDir" in line:
            base_type = "files"
    
    if dir_name:
        # ì´ë¯¸ ì ‘ë‘ì‚¬ê°€ ë¶™ì–´ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if dir_name.startswith("cache/") or dir_name.startswith("files/"):
            return dir_name
        
        # âœ… ìˆ˜ì •: base_typeì´ Noneì´ë©´ ì¶”ë¡ 
        if not base_type:
            # ì´ë¦„ ê¸°ë°˜ ì¶”ë¡ 
            if "cache" in dir_name.lower() or dir_name.startswith("app_"):
                base_type = "cache"
            else:
                base_type = "files"
        
        # base_type ì ‘ë‘ì‚¬ ì¶”ê°€
        return f"{base_type}/{dir_name}"
    
    return None


def extract_meta_storage_universal(method) -> Dict[int, str]:
    """
    ë²”ìš© Meta Storage ID ì¶”ì¶œ ì—”ì§„
    """
    print(f"\n{'='*80}")
    print(f"[UNIVERSAL-EXTRACT] ì‹œì‘: {method.get_class_name()}->{method.get_name()}")
    print(f"{'='*80}")
    
    try:
        insns = list(method.get_instructions())
        print(f"[UNIVERSAL] ì´ {len(insns)}ê°œ instruction")
        
        # 1. sparse-switch ì°¾ê¸°
        switch_idx = None
        for idx, ins in enumerate(insns):
            if ins.get_name() == "sparse-switch":
                switch_idx = idx
                print(f"[UNIVERSAL] âœ“ sparse-switch ë°œê²¬: idx={idx}")
                break
        
        if switch_idx is None:
            print(f"[UNIVERSAL] âœ— sparse-switch ì—†ìŒ")
            return {}
        
        # 2. payload instruction ì§ì ‘ ì°¾ê¸°
        # payloadëŠ” sparse-switch-payloadë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ instruction
        payload_idx = None
        for idx, ins in enumerate(insns):
            if "sparse-switch-payload" in ins.get_name():
                payload_idx = idx
                print(f"[UNIVERSAL] âœ“ payload ë°œê²¬: idx={idx}")
                break
        
        if payload_idx is None:
            print(f"[UNIVERSAL] âœ— payload instruction ì—†ìŒ")
            return {}
        
        payload_ins = insns[payload_idx]
        
        # 3. payload íŒŒì‹± (storage ID ëª©ë¡ ì¶”ì¶œ)
        print(f"[UNIVERSAL] payload íŒŒì‹± ì‹œì‘...")
        storage_ids = _parse_sparse_switch_unified(payload_ins)  # â† List[int] ë°˜í™˜!
        print(f"[UNIVERSAL] íŒŒì‹± ì™„ë£Œ: {len(storage_ids)}ê°œ storage ID")

        if not storage_ids:
            print(f"[UNIVERSAL] âœ— payload íŒŒì‹± ê²°ê³¼ ì—†ìŒ")
            return {}

        # 4. case ë¸”ë¡ ìœ„ì¹˜ ì°¾ê¸° (payload ë‹¤ìŒë¶€í„° ìˆœì°¨ ìŠ¤ìº”)
        # Facebook Lite ë°”ì´íŠ¸ì½”ë“œë¥¼ ë³´ë©´:
        #   idx=62: sparse-switch-payload
        #   idx=12: const-string "lib-compressed"  â† ì²« ë²ˆì§¸ case
        #   idx=14: const-string "app_secure_shared" â† ë‘ ë²ˆì§¸ case
        #   ...
        # ì¦‰, payload ì´í›„ê°€ ì•„ë‹ˆë¼ **switch ì´í›„ë¶€í„°** case ë¸”ë¡ ì‹œì‘!

        print(f"\n[UNIVERSAL] case ë¸”ë¡ ìœ„ì¹˜ ê³„ì‚° ì‹œì‘...")

        # ë°”ì´íŠ¸ì½”ë“œì—ì„œ const-stringìœ¼ë¡œ case ë¸”ë¡ ì°¾ê¸°
        case_blocks = []
        for idx in range(switch_idx + 1, len(insns)):
            ins = insns[idx]
            
            # const-stringë§Œ case ë¸”ë¡ìœ¼ë¡œ ê°„ì£¼
            if "const-string" in ins.get_name():
                output = ins.get_output()
                # ì—ëŸ¬ ë©”ì‹œì§€ ì œì™¸
                if "Storage config" not in output and "not in startup" not in output:
                    case_blocks.append(idx)
                    # storage_ids ê°œìˆ˜ë§Œí¼ë§Œ ìˆ˜ì§‘
                    if len(case_blocks) >= len(storage_ids):
                        break

        print(f"[UNIVERSAL] âœ“ {len(case_blocks)}ê°œ case ë¸”ë¡ ë°œê²¬")

        # 5. storage_idì™€ case_block ë§¤í•‘
        mapping = {}
        print(f"\n[UNIVERSAL] ID â†’ ë””ë ‰í„°ë¦¬ ë§¤í•‘ ì‹œì‘...")

        for i, storage_id in enumerate(storage_ids):
            if i >= len(case_blocks):
                print(f"  [CASE] ID={storage_id:#x} âœ— case ë¸”ë¡ ë¶€ì¡±")
                break
            
            case_idx = case_blocks[i]
            print(f"\n  [CASE] ID={storage_id:#x}, case_idx={case_idx}")
            
            # âœ… ì—¬ê¸°ì„œë¶€í„°ëŠ” ê¸°ì¡´ ì½”ë“œ ìœ ì§€!
            dir_name = _extract_dir_from_case_block(insns, case_idx)
            
            if dir_name:
                print(f"    âœ“ ì¶”ì¶œ: '{dir_name}'")
                mapping[storage_id] = dir_name
            else:
                print(f"    âœ— ë””ë ‰í„°ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨")

        print(f"\n[UNIVERSAL] ìµœì¢… ê²°ê³¼: {len(mapping)}ê°œ ë§¤í•‘")
        for sid, sdir in sorted(mapping.items()):
            print(f"  {sid:#x} â†’ {sdir}")

        return mapping
    
    except Exception as e:
        print(f"[UNIVERSAL] âœ— ì˜ˆì™¸ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return {}




def find_meta_storage_classes(dx) -> List[str]:
    import sys
    
    def dual_print(msg: str):
        sys.stderr.write(msg + "\n")
        sys.stderr.flush()
        print(msg)
    
    dual_print("\n" + "ğŸ¯"*40)
    dual_print("[FIND-META] find_meta_storage_classes() í˜¸ì¶œë¨!")
    dual_print("ğŸ¯"*40 + "\n")

    # ===== âœ… ì¶”ê°€: ì•Œë ¤ì§„ í´ë˜ìŠ¤ í•˜ë“œì½”ë”© ì²´í¬ (ë¹ ë¥¸ ê²½ë¡œ) =====
    KNOWN_CLASSES = {
        "LX/1AW;",   # Facebook
        "LX/BX8;",   # Instagram
        "LX/191;",   # Threads
        "LX/0Ah;",   # Facebook Lite
        "LX/0AH;",   # Instagram Lite
    }

    dual_print("[META-Auto] 1ë‹¨ê³„: ì•Œë ¤ì§„ í´ë˜ìŠ¤ ì²´í¬...")
    known_found = []
    for cls_analysis in dx.get_classes():
        try:
            cls = _get_vm_class(cls_analysis)  # â† ê¸°ì¡´ í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©
            if not cls:
                continue
            cls_name = cls.get_name()
            if cls_name in KNOWN_CLASSES:
                dual_print(f"  âœ“ ë°œê²¬: {cls_name}")
                known_found.append(cls_name)
        except:
            continue
    
    if known_found:
        dual_print(f"[META-Auto] âœ“ {len(known_found)}ê°œ ì•Œë ¤ì§„ í´ë˜ìŠ¤ ë°œê²¬!")
        dual_print("="*80 + "\n")
        return known_found  # â† ì—¬ê¸°ì„œ ì¦‰ì‹œ ë¦¬í„´!
    
    # ===== ê¸°ì¡´ ë¡œì§ (í•˜ë“œì½”ë”© ì‹¤íŒ¨ ì‹œì—ë§Œ ì‹¤í–‰ë¨) =====
    dual_print("[META-Auto] 2ë‹¨ê³„: íŒ¨í„´ ê¸°ë°˜ íƒì§€...")
    
    candidates = []
    checked_classes = set()
    context_int_file_methods = []

    dual_print("[META-Auto] ë©”ì„œë“œ ìŠ¤ìº” ì¤‘...")

    total_methods = 0
    methods_with_code = 0
    context_file_methods = 0
    
    for ma in dx.get_methods():
        total_methods += 1
        
        # ===== ë””ë²„ê¹…: ì²« 10ê°œ ë©”ì„œë“œ ìƒì„¸ ë¡œê·¸ =====
        if total_methods <= 10:
            dual_print(f"[DEBUG] Method #{total_methods}: {ma}")

        try:
            em = ma.get_method()
            
            # ===== ë””ë²„ê¹…: ë©”ì„œë“œ ì •ë³´ =====
            if total_methods <= 5:
                dual_print(f"  - Class: {em.get_class_name()}")
                dual_print(f"  - Name: {em.get_name()}")
                dual_print(f"  - Descriptor: {em.get_descriptor()}")
            
            desc = em.get_descriptor()
            cls_name = em.get_class_name()
            
            # ì½”ë“œ ì¡´ì¬ ì—¬ë¶€ ì¹´ìš´íŠ¸
            code = em.get_code()
            if code:
                methods_with_code += 1
            
            # ì¤‘ë³µ í´ë˜ìŠ¤ ìŠ¤í‚µ
            if cls_name in checked_classes:
                continue

            # ===== Context â†’ File ê²€ì‚¬ (ì™„í™”ëœ ë²„ì „) =====
            if "Landroid/content/Context;" in desc:
                context_file_methods += 1
                
                # ===== ë””ë²„ê¹…: Context ë©”ì„œë“œ ì¶œë ¥ =====
                if context_file_methods <= 10:
                    dual_print(f"[DEBUG] Context method: {cls_name}->{em.get_name()}{desc}")
                
                if desc.endswith(")Ljava/io/File;"):
                    has_int = (";I" in desc or ";I)" in desc or ";J" in desc or ";J)" in desc)
                    
                    if has_int:
                        has_code = "ìˆìŒ" if code else "ì—†ìŒ"
                        context_int_file_methods.append(
                            f"{cls_name}->{em.get_name()}{desc} [ì½”ë“œ:{has_code}]"
                        )
                        
                        # ===== ë””ë²„ê¹…: ë°œê²¬ ì¦‰ì‹œ ì¶œë ¥ =====
                        dual_print(f"  âœ“ ë°œê²¬! {cls_name}->{em.get_name()}")
            
            # ===== ì›ë˜ íŒ¨í„´ ë§¤ì¹­ ë¡œì§ =====
            if "Landroid/content/Context;" not in desc:
                continue
            if not desc.endswith(")Ljava/io/File;"):
                continue
            
            has_int = (";I" in desc or ";I)" in desc or ";J" in desc or ";J)" in desc)
            if not has_int:
                continue
            
            checked_classes.add(cls_name)
            
            if not code:
                continue
            
            # smali í…ìŠ¤íŠ¸ ì¶”ì¶œ
            bc = code.get_bc()
            insns = list(bc.get_instructions())
            insns_text = "\n".join(ins.get_output() for ins in insns)
            
            # íŒ¨í„´ ê²€ì¦
            has_sparse_switch = "sparse-switch" in insns_text
            has_storage_error = "Storage config" in insns_text
            has_registry_error = "not in startup registry" in insns_text
            
            score = sum([has_sparse_switch, has_storage_error, has_registry_error])
            
            if score >= 1:
                dual_print(f"  [í›„ë³´] {cls_name} (ì ìˆ˜: {score}/3)")
                dual_print(f"    - sparse-switch: {has_sparse_switch}")
                dual_print(f"    - Storage config: {has_storage_error}")
                dual_print(f"    - registry error: {has_registry_error}")
            
            if score >= 2:
                candidates.append(cls_name)
                dual_print(f"  âœ“ ì±„íƒ: {cls_name}")
        
        except Exception as e:
            if total_methods <= 10:
                dual_print(f"[DEBUG] Method #{total_methods} ì—ëŸ¬: {e}")
            continue
    
    # ===== ìµœì¢… í†µê³„ =====
    dual_print("\n" + "="*80)
    dual_print("[FIND-META] ìŠ¤ìº” ì™„ë£Œ!")
    dual_print(f"  ì´ ë©”ì„œë“œ ìˆ˜: {total_methods}")
    dual_print(f"  ì½”ë“œ ìˆëŠ” ë©”ì„œë“œ: {methods_with_code}")
    dual_print(f"  Context ë©”ì„œë“œ: {context_file_methods}")
    dual_print(f"  Context+intâ†’File: {len(context_int_file_methods)}ê°œ")
    dual_print(f"  ìµœì¢… í›„ë³´ í´ë˜ìŠ¤: {len(candidates)}ê°œ")
    dual_print("="*80 + "\n")

    # ===== ë””ë²„ê·¸ ì¶œë ¥ =====
    dual_print(f"\n[DEBUG] Context+intâ†’File ë©”ì„œë“œ ì´ {len(context_int_file_methods)}ê°œ:")
    for i, method in enumerate(context_int_file_methods[:20], 1):
        dual_print(f"  {i}. {method}")
    if len(context_int_file_methods) > 20:
        dual_print(f"  ... (+{len(context_int_file_methods)-20}ê°œ ë”)")
    
    # íŒŒì¼ë¡œë„ ì €ì¥
    with open("debug_context_file_methods.txt", "w", encoding="utf-8") as f:
        for method in context_int_file_methods:
            f.write(method + "\n")
    dual_print(f"\n[DEBUG] âœ“ ì „ì²´ ëª©ë¡ ì €ì¥: debug_context_file_methods.txt\n")
    
    return candidates


def analyze_context_file_methods(dx):
    """
    Context â†’ File ë©”ì„œë“œì˜ ì‹¤ì œ ì½”ë“œ ë¶„ì„
    (ìë™ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë¶„ì„ìš©)
    """
    import sys
    
    def dual_print(msg: str):
        sys.stderr.write(msg + "\n")
        sys.stderr.flush()
        print(msg)
    
    dual_print("\n" + "="*80)
    dual_print("[ANALYZE] Contextâ†’File ë©”ì„œë“œ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
    
    target_methods = []
    
    # Context â†’ File ë©”ì„œë“œ ìˆ˜ì§‘
    for ma in dx.get_methods():
        try:
            em = ma.get_method()
            cls_name = em.get_class_name()
            desc = em.get_descriptor()
            
            # Context â†’ File ë©”ì„œë“œë§Œ
            if "Landroid/content/Context;" in desc and desc.endswith(")Ljava/io/File;"):
                target_methods.append((cls_name, em.get_name(), desc, em))
        except Exception:
            continue
    
    dual_print(f"[ANALYZE] ì´ {len(target_methods)}ê°œ ë©”ì„œë“œ ë°œê²¬")
    
    # ìƒìœ„ 20ê°œë§Œ ìƒì„¸ ë¶„ì„
    for i, (cls, name, desc, em) in enumerate(target_methods[:20]):
        dual_print(f"\n{'='*80}")
        dual_print(f"[METHOD #{i+1}] {cls}->{name}{desc}")
        
        code = em.get_code()
        if not code:
            dual_print("  [SKIP] ì½”ë“œ ì—†ìŒ")
            continue
        
        try:
            # ë°”ì´íŠ¸ì½”ë“œ ì •ë³´
            bc = code.get_bc()
            insns = list(bc.get_instructions())
            dual_print(f"  [CODE] Instructions: {len(insns)}")
            
            # ë¬¸ìì—´ ìˆ˜ì§‘
            strings_found = []
            for insn in insns:
                op = insn.get_name()
                if 'const-string' in op:
                    output = insn.get_output()
                    if '"' in output:
                        # "xxx" í˜•íƒœì—ì„œ xxx ì¶”ì¶œ
                        parts = output.split('"')
                        if len(parts) >= 2:
                            strings_found.append(parts[1])
            
            if strings_found:
                dual_print(f"  [STRINGS] {len(strings_found)}ê°œ ë°œê²¬:")
                for s in strings_found[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                    dual_print(f"    â†’ {s}")
            else:
                dual_print(f"  [STRINGS] ì—†ìŒ")
            
            # sparse-switch ì²´í¬
            smali_text = "\n".join(insn.get_output() for insn in insns)
            has_sparse = 'sparse-switch' in smali_text
            dual_print(f"  [SPARSE-SWITCH] {'âœ“' if has_sparse else 'âœ—'}")
            
            # ifë¬¸ ì²´í¬
            if_count = sum(1 for insn in insns if 'if-' in insn.get_name())
            dual_print(f"  [IF-STATEMENTS] {if_count}ê°œ")
            
        except Exception as e:
            dual_print(f"  [ERROR] ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    dual_print("\n" + "="*80)
    dual_print("[ANALYZE] ë¶„ì„ ì™„ë£Œ!")


def dump_method_bytecode_detail(dx, target_signature: str):
    """
    íŠ¹ì • ë©”ì„œë“œì˜ ë°”ì´íŠ¸ì½”ë“œë¥¼ ìƒì„¸íˆ ë¤í”„
    
    Args:
        target_signature: "LX/0Ah;->A00(Landroid/content/Context;I)Ljava/io/File;"
    """
    import sys
    
    def dual_print(msg: str):
        sys.stderr.write(msg + "\n")
        sys.stderr.flush()
        print(msg)
    
    dual_print("\n" + "ğŸ”¬"*40)
    dual_print(f"[BYTECODE-DUMP] íƒ€ê²Ÿ: {target_signature}")
    dual_print("ğŸ”¬"*40 + "\n")
    
    target_found = False
    
    for ma in dx.get_methods():
        try:
            em = ma.get_method()
            cls_name = em.get_class_name()  # â† ì´ë¯¸ "LX/0Ah;" í˜•íƒœ (ì„¸ë¯¸ì½œë¡  í¬í•¨!)
            method_name = em.get_name()
            desc = em.get_descriptor()
            
            # âœ… ìˆ˜ì •: í´ë˜ìŠ¤ ì´ë¦„ì— ì´ë¯¸ ì„¸ë¯¸ì½œë¡  ìˆìŒ
            full_sig = f"{cls_name}->{method_name}{desc}"
            
            # ì •ê·œí™”í•´ì„œ ë¹„êµ (ê³µë°±/ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            full_sig_normalized = norm_sig(full_sig)
            target_normalized = norm_sig(target_signature)
            
            if full_sig_normalized != target_normalized:
                continue
            
            target_found = True
            dual_print(f"[FOUND] ë©”ì„œë“œ ë°œê²¬!")
            dual_print(f"  í´ë˜ìŠ¤: {cls_name}")
            dual_print(f"  ë©”ì„œë“œ: {method_name}")
            dual_print(f"  ì‹œê·¸ë‹ˆì²˜: {desc}\n")
            
            code = em.get_code()
            if not code:
                dual_print("[ERROR] ì½”ë“œ ì—†ìŒ!")
                return
            
            bc = code.get_bc()
            insns = list(bc.get_instructions())
            
            dual_print(f"[INFO] ì´ {len(insns)}ê°œ instruction\n")
            dual_print("="*80)
            
            # ì „ì²´ ë°”ì´íŠ¸ì½”ë“œ ë¤í”„
            for i, ins in enumerate(insns):
                op = ins.get_name()
                output = ins.get_output()
                
                # ì¤‘ìš” instruction ê°•ì¡°
                marker = ""
                if "const" in op:
                    marker = "ğŸ“Œ "
                elif "invoke" in op:
                    marker = "ğŸ”§ "
                elif "if-" in op:
                    marker = "ğŸ”€ "
                elif "return" in op:
                    marker = "â†©ï¸  "
                elif "sget" in op or "sput" in op:
                    marker = "ğŸ—‚ï¸  "
                elif "new-" in op:
                    marker = "ğŸ†• "
                
                dual_print(f"{marker}{i:4d} | {op:30s} | {output}")
            
            dual_print("\n" + "="*80)
            
            # íŠ¹ìˆ˜ íŒ¨í„´ ë¶„ì„
            dual_print("\n[PATTERN-ANALYSIS]")
            
            # 1. static í•„ë“œ ì ‘ê·¼
            sget_fields = []
            for i, ins in enumerate(insns):
                if "sget" in ins.get_name():
                    sget_fields.append((i, ins.get_output()))
            
            if sget_fields:
                dual_print(f"\nâœ“ Static í•„ë“œ ì ‘ê·¼ {len(sget_fields)}ê°œ:")
                for idx, output in sget_fields[:10]:
                    dual_print(f"  [{idx:4d}] {output}")
            
            # 2. invoke í˜¸ì¶œ
            invokes = []
            for i, ins in enumerate(insns):
                if "invoke" in ins.get_name():
                    invokes.append((i, ins.get_output()))
            
            if invokes:
                dual_print(f"\nâœ“ ë©”ì„œë“œ í˜¸ì¶œ {len(invokes)}ê°œ:")
                for idx, output in invokes[:10]:
                    dual_print(f"  [{idx:4d}] {output}")
            
            # 3. ìƒìˆ˜ê°’
            consts = []
            for i, ins in enumerate(insns):
                op = ins.get_name()
                if "const" in op:
                    consts.append((i, op, ins.get_output()))
            
            if consts:
                dual_print(f"\nâœ“ ìƒìˆ˜ {len(consts)}ê°œ:")
                for idx, op, output in consts[:20]:
                    dual_print(f"  [{idx:4d}] {op:20s} | {output}")
            
            # 4. ifë¬¸ ë¶„ê¸°
            ifs = []
            for i, ins in enumerate(insns):
                if "if-" in ins.get_name():
                    ifs.append((i, ins.get_output()))
            
            if ifs:
                dual_print(f"\nâœ“ ì¡°ê±´ ë¶„ê¸° {len(ifs)}ê°œ:")
                for idx, output in ifs:
                    dual_print(f"  [{idx:4d}] {output}")
            
            dual_print("\n" + "ğŸ”¬"*40)
            dual_print("[BYTECODE-DUMP] ì™„ë£Œ!")
            dual_print("ğŸ”¬"*40 + "\n")
            
            break
            
        except Exception as e:
            continue
    
    if not target_found:
        dual_print("[ERROR] íƒ€ê²Ÿ ë©”ì„œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ!")


def extract_meta_storage_ids_from_dex(dx) -> Dict[int, str]:
    import sys
    
    msg = "\n" + "ğŸ”"*40 + "\n[EXTRACT-META] Meta Storage ì¶”ì¶œ ì‹œì‘\n" + "ğŸ”"*40 + "\n"
    sys.stderr.write(msg)
    sys.stderr.flush()
    print(msg)

    meta_classes = find_meta_storage_classes(dx)
    
    if not meta_classes:
        sys.stderr.write("[META-Auto] âŒ í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\n")
        sys.stderr.flush()
        return {}
    
    print(f"[META-Auto] âœ“ {len(meta_classes)}ê°œ í´ë˜ìŠ¤ ë°œê²¬")
    
    mapping = {}
    
    for target_class in meta_classes:
        print(f"\n[META-Auto] {target_class} ë¶„ì„ ì¤‘...")
        
        method_count = 0
        matched_count = 0
        
        for ma in dx.get_methods():
            try:
                em = ma.get_method()
                
                if em.get_class_name() != target_class:
                    continue
                
                method_count += 1
                
                desc = em.get_descriptor()
                method_name = em.get_name()
                
                print(f"  [SCAN] {method_name}{desc}")
                
                # âœ… ìˆ˜ì •ëœ ì‹œê·¸ë‹ˆì²˜ ì²´í¬ (ê³µë°± í—ˆìš©)
                # ê³µë°± ì œê±° í›„ ì²´í¬
                desc_normalized = desc.replace(" ", "")
                
                is_storage_method = (
                    # File ë¦¬í„´í•˜ê³  int íŒŒë¼ë¯¸í„° ìˆëŠ” ë©”ì„œë“œ
                    (";I)" in desc_normalized and desc_normalized.endswith(")Ljava/io/File;")) or
                    # String ë¦¬í„´í•˜ê³  int íŒŒë¼ë¯¸í„°ë§Œ ìˆëŠ” ë©”ì„œë“œ
                    (desc_normalized == "(I)Ljava/lang/String;")
                )
                
                print(f"    â†’ ë§¤ì¹­: {is_storage_method}")
                
                if not is_storage_method:
                    continue
                
                matched_count += 1
                print(f"    âœ“ Storage ë©”ì„œë“œ ë°œê²¬!")
                
                print(f"    â†’ extract_meta_storage_universal() í˜¸ì¶œ...")
                extracted = extract_meta_storage_universal(em)
                print(f"    â†’ ì¶”ì¶œ ê²°ê³¼: {len(extracted)}ê°œ")
                
                if extracted:
                    mapping.update(extracted)
                    print(f"  âœ“ {len(extracted)}ê°œ ë§¤í•‘ ì¶”ì¶œ (ë©”ì„œë“œ: {em.get_name()})")
                    break
                else:
                    print(f"  âš ï¸ ì¶”ì¶œ ê²°ê³¼ 0ê°œ (ë©”ì„œë“œëŠ” ì°¾ì•˜ìœ¼ë‚˜ ë°ì´í„° ì—†ìŒ)")
            
            except Exception as e:
                print(f"  [ERROR] ë©”ì„œë“œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"  [STAT] {target_class}: ë©”ì„œë“œ {method_count}ê°œ, ë§¤ì¹­ {matched_count}ê°œ")
    
    print(f"\n[META-Auto] === ìµœì¢…: {len(mapping)}ê°œ ë§¤í•‘ ===\n")
    return mapping


# ========== ê³µí†µ ==========
def _sanitize_str_for_json(s: str) -> str:
    return s.encode("utf-8", "replace").decode("utf-8")

def sanitize_for_json(obj):
    if obj is None:
        return None
    if isinstance(obj, str):
        return _sanitize_str_for_json(obj)
    if isinstance(obj, (int, float, bool)):
        return obj
    if isinstance(obj, dict):
        return {sanitize_for_json(k): sanitize_for_json(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple, set)):
        t = [sanitize_for_json(x) for x in obj]
        return t if not isinstance(obj, tuple) else tuple(t)
    try:
        return _sanitize_str_for_json(str(obj))
    except Exception:
        return None

def norm_sig(s: str) -> str:
    if not s:
        return ""
    s = s.replace("\ufeff", "").replace("\u200b", "")
    s = re.sub(r"\s+", "", s)
    return s

def _dequote(s: Optional[str]) -> str:
    """ë¬¸ìì—´ ì–‘ë ë”°ì˜´í‘œ ì œê±°."""
    if not s:
        return ""
    s = str(s).strip()
    if len(s) >= 2 and s[0] == s[-1] and s[0] in ("'", '"'):
        return s[1:-1].strip()
    return s

INVOKE_OPS = {
    "invoke-virtual","invoke-direct","invoke-static","invoke-interface","invoke-super","invoke-polymorphic",
    "invoke-virtual/range","invoke-direct/range","invoke-static/range","invoke-interface/range","invoke-super/range"
}
MOVE_RESULT_OPS = {"move-result-object","move-result","move-result-wide"}
MOVE_OPS = {
    "move","move-object","move-wide",
    "move/from16","move-object/from16","move-wide/from16",
    "move/16","move-object/16","move-wide/16"
}
CONST_STRING_OPS = {"const-string","const-string/jumbo"}

IPUT_OPS = {"iput","iput-object","iput-boolean","iput-byte","iput-char","iput-short","iput-wide"}
SPUT_OPS = {"sput","sput-object","sput-boolean","sput-byte","sput-char","sput-short","sput-wide"}
IGET_OPS = {"iget","iget-object","iget-boolean","iget-byte","iget-char","iget-short","iget-wide"}
SGET_OPS = {"sget","sget-object","sget-boolean","sget-byte","sget-char","sget-short","sget-wide"}

# ---- ê²½ë¡œ ì¡°í•© íŒ¨í„´(í™•ì¥) ----
JOIN_METHOD_PATTERNS = (
    "->resolve(Ljava/lang/String;)",
    "->child(Ljava/lang/String;)",
    "->appendPath(Ljava/lang/String;)",
    "->append(Ljava/lang/String;)",
    "->addPathSegment(Ljava/lang/String;)",
    "->appendEncodedPath(Ljava/lang/String;)",
    "Ljava/nio/file/Path;->resolve(Ljava/lang/String;)",
    "Ljava/io/File;-><init>(Ljava/io/File;Ljava/lang/String;)",  # joinì²˜ëŸ¼ ì·¨ê¸‰
    "Landroid/net/Uri;->withAppendedPath(",
)

PATH_BASES_TEMPL = [
    "/data/user/0/{pkg}/cache",
    "/data/user/0/{pkg}/files",
    "/data/user/0/{pkg}/code_cache",
    "/data/user/0/{pkg}/databases",
    "/data/user/0/{pkg}/shared_prefs",
    "/data/user/0/{pkg}/app_",
    "/data/user/0/{pkg}/files/app_webview",
    "/storage/emulated/0/Android/data/{pkg}/cache",
    "/storage/emulated/0/Android/data/{pkg}/files",
    "/sdcard/android/data/{pkg}/cache",
    "/sdcard/android/data/{pkg}/files",
]

# ---- ë¬¸ìì—´ ë¹Œë” ----
STRINGBUILDER_PATTERNS = (
    "Ljava/lang/StringBuilder;->append(",
    "Ljava/lang/StringBuffer;->append(",
)
STRINGBUILDER_TOSTRING_PATTERNS = (
    "Ljava/lang/StringBuilder;->toString()",
    "Ljava/lang/StringBuffer;->toString()",
)

# ---- ìƒì„±ì/ìŠ¤íŠ¸ë¦¼ë¥˜ prefix ----
ALWAYS_CREATION_SINK_PREFIXES = (
    "Ljava/io/File;-><init>(",
    "Ljava/io/FileOutputStream;-><init>(",
    "Ljava/io/FileInputStream;-><init>(",
    "Ljava/io/RandomAccessFile;-><init>(",
)

# ---- ë””ë ‰í„°ë¦¬ ì„¸í„°/ìºì‹œ ì§€ì •/DB íŒíŠ¸(í™•ì¥) ----
DIR_LIKE_SINK_PATTERNS = (
    "->directory(",
    "->setDirectory(",
    "->diskCache(",
    "->setDiskCache(",
    "->cacheSubdirectory(",
    "->cacheDir(",
    "->cacheDirectory(",
    "->setCacheDirectory(",
    "Landroidx/room/Room;->databaseBuilder(",
    "Lokhttp3/Cache;-><init>(",
    "Lcom/google/android/exoplayer2/upstream/cache/SimpleCache;-><init>(",
)

# ---- ë² ì´ìŠ¤ ë””ë ‰í„°ë¦¬ ê·œì¹™ í…Œì´ë¸”(ì •ê·œì‹ â†’ ì ˆëŒ€ê²½ë¡œ í…œí”Œë¦¿) ----
BASE_DIR_RULES: List[Tuple[re.Pattern, callable]] = [
    # hx.fxn()
    (re.compile(r"^Lcom/bytedance/sdk/component/adexpress/fxn/kg/hm;->fxn\(\)Ljava/io/File;$"
    ),lambda pkg, args, ro: f"/data/user/0/{pkg}/cache"),
    # sg.fxn(Context, boolean, String)
    (re.compile(r"^Lcom/bytedance/sdk/component/utils/sg;->fxn\(Landroid/content/Context;ZLjava/lang/String;\)Ljava/io/File;$"
    ),lambda pkg, args, ro: (f"/data/user/0/{pkg}/cache/" + (ro.get(args[2], {}).get("value")).strip("/"))
    ),

    # ë‚´ë¶€ ì €ì¥ì†Œ
    (re.compile(r"^L[^;]+;->getCacheDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/cache"),
    (re.compile(r"^L[^;]+;->getFilesDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files"),
    (re.compile(r"^L[^;]+;->getNoBackupFilesDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/no_backup"),
    (re.compile(r"^L[^;]+;->getCodeCacheDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/code_cache"),
    (re.compile(r"^L[^;]+;->getObbDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/storage/emulated/0/Android/obb/{pkg}"),
    (re.compile(r"^L[^;]+;->getObbDirs\(\)\[Ljava/io/File;$"),
     lambda pkg,args,ro: f"/storage/emulated/0/Android/obb/{pkg}"),

    # ì™¸ë¶€(ì•± ì „ìš©)
    (re.compile(r"^L[^;]+;->getExternalCacheDir\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/storage/emulated/0/Android/data/{pkg}/cache"),
    (re.compile(r"^L[^;]+;->getExternalCacheDirs\(\)\[Ljava/io/File;$"),
     lambda pkg,args,ro: f"/storage/emulated/0/Android/data/{pkg}/cache"),
    (re.compile(r"^L[^;]+;->getExternalFilesDir\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: (
        f"/storage/emulated/0/Android/data/{pkg}/files"
        + (f"/{(ro.get(args[1],{}).get('value') or '').strip('/')}" if len(args) >= 2 and args[1] in ro else "")
     )),
    (re.compile(r"^L[^;]+;->getExternalFilesDirs\(Ljava/lang/String;\)\[Ljava/io/File;$"),
     lambda pkg,args,ro: (
        f"/storage/emulated/0/Android/data/{pkg}/files"
        + (f"/{(ro.get(args[1],{}).get('value') or '').strip('/')}" if len(args) >= 2 and args[1] in ro else "")
     )),

    # ì¡°í•©í˜•
    (re.compile(r"^L[^;]+;->getDir\(Ljava/lang/String;I\)Ljava/io/File;$"),
     lambda pkg,args,ro: (
        (f"/data/user/0/{pkg}/app_webview" if ((ro.get(args[1],{}) or {}).get("value","").strip().lower()=="webview") else 
         f"/data/user/0/{pkg}/app_{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'name')}")
     )),
    (re.compile(r"^L[^;]+;->getDatabasePath\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/databases/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'db')}"),
    (re.compile(r"^L[^;]+;->getFileStreamPath\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'file')}"),

    # Environment
    (re.compile(r"^Landroid/os/Environment;->getExternalStorageDirectory\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: "/storage/emulated/0"),

    # ì»¤ìŠ¤í…€ getterë¥˜
    (re.compile(r"^L[^;]+;->getCacheDirectory\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/cache"),
    (re.compile(r"^L[^;]+;->get[A-Za-z0-9_]*Cache[A-Za-z0-9_]*\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/cache"),
    (re.compile(r"^L[^;]+;->get[A-Za-z0-9_]*File[s]?[A-Za-z0-9_]*\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files"),

    # DataStore ì „ìš© ê·œì¹™
    (re.compile(r"^Landroidx/datastore/preferences/core/PreferenceDataStoreFileKt;->preferencesDataStoreFile\(Landroid/content/Context;Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/datastore/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'datastore')}.preferences_pb"),
    (re.compile(r"^Landroidx/datastore/preferences/core/PreferenceDataStoreFileKt;->PreferenceDataStoreFile\(Landroid/content/Context;Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/datastore/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'datastore')}.preferences_pb"),
    (re.compile(r"^Landroidx/datastore/core/DataStoreFactory;->create\(.*\)Landroidx/datastore/core/DataStore;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/datastore/"),
    (re.compile(r"^Landroid/content/Context;->getDataStoreFile\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/datastore/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'datastore')}.preferences_pb"),
    (re.compile(r"^Landroidx/datastore/.+;->dataStoreFile\(Landroid/content/Context;Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: f"/data/user/0/{pkg}/files/datastore/{(ro.get(args[1],{}).get('value') if len(args)>=2 and args[1] in ro else 'datastore')}.preferences_pb"),

    # [NEW] ì™¸ë¶€ ì €ì¥ì†Œ í•˜ìœ„ ë””ë ‰í„°ë¦¬ íŒ¨í„´
    (re.compile(r"^L[^;]+;->getExternalFilesDir\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: (
        f"/sdcard/Android/data/{pkg}/files"
        + (f"/{(ro.get(args[1],{}).get('value') or '').strip('/')}" if len(args) >= 2 and args[1] in ro else "")
     )),

    # [NEW] /storage/emulated/0 -> /sdcard ë™ì¹˜
    (re.compile(r"^Landroid/os/Environment;->getExternalStorageDirectory\(\)Ljava/io/File;$"),
     lambda pkg,args,ro: "/sdcard"),

    # [NEW] DIRECTORY_PICTURES ë“±
    (re.compile(r"^Landroid/os/Environment;->getExternalStoragePublicDirectory\(Ljava/lang/String;\)Ljava/io/File;$"),
     lambda pkg,args,ro: (
        "/sdcard"
        + (f"/{(ro.get(args[0],{}).get('value') or 'Download').strip('/')}" if args and args[0] in ro else "/Download")
     )),
]

# ---- DataStore wrapper detection (ë²”ìš© ì •ê·œì‹) ----
DS_WRAPPER_RES = [
    re.compile(r'\bsafePreferencesDataStore\(', re.I),
    re.compile(r'\bsecurePreferencesDataStore\(', re.I),
    re.compile(r'\bfastPreferencesDataStore\(', re.I),
    re.compile(r'\b[A-Za-z0-9_]*PreferencesDataStore\(', re.I),  
]

# ========== ë¡œê±° ==========
class DualLogger:
    def __init__(self, enabled=False, path="debug_log.txt"):
        self.enabled = enabled
        self.file = None
        if enabled:
            self.file = open(path, "w", encoding="utf-8")
            self.file.write(f"[DEBUG START {datetime.now()}]\n")

    def log(self, msg: str):
        print(msg)
        if self.enabled and self.file:
            self.file.write(msg + "\n")
            self.file.flush()

    def close(self):
        if self.file:
            self.file.write("[DEBUG END]\n")
            self.file.close()

logger = DualLogger(False)

# ========== ì•ˆë“œë¡œê°€ë“œ ë¡œë” ==========
def load_with_fallback(apk_path: str):
    from androguard.misc import AnalyzeAPK
    from androguard.core.analysis.analysis import Analysis

    try:
        a, d, dx = AnalyzeAPK(apk_path)
        code_cnt = 0
        for ma in dx.get_methods():
            try:
                if ma.get_method().get_code() is not None:
                    code_cnt += 1
            except Exception:
                pass
        if code_cnt > 0:
            return a, dx
        else:
            print(f"[WARN] AnalyzeAPK returned 0 methods with code; trying manual loader...")
    except Exception as e:
        print(f"[WARN] AnalyzeAPK() failed: {e!r}; trying manual loader...")

    try:
        from androguard.core.bytecodes import apk, dvm
        a = apk.APK(apk_path)
        dex_bytes_list = a.get_all_dex()
        if not dex_bytes_list:
            raise RuntimeError("No classes*.dex found inside APK")

        dx = Analysis()
        for dex in dex_bytes_list:
            vm = dvm.DalvikVMFormat(dex)
            dx.add(vm)

        try:
            dx.create_xref()
        except Exception:
            pass

        code_cnt = 0
        for ma in dx.get_methods():
            try:
                if ma.get_method().get_code() is not None:
                    code_cnt += 1
            except Exception:
                pass

        if code_cnt > 0:
            print(f"[INFO] manual loader succeeded: methods with code={code_cnt}")
            return a, dx
        else:
            raise RuntimeError("manual loader still has 0 methods with code")
    except Exception as e2:
        raise RuntimeError(f"All loaders failed or no code found: {e2!r}")


# ========== Meta storage config (LX/191 ë“±) sparse-switch ë¶„ì„ê¸° ==========
_SPARSE_SWITCH_TABLE_RE = re.compile(
    r':(sswitch_data_[0-9a-fA-F]+)\s*\n'
    r'((?:\s*0x[0-9a-fA-F]+\s*->\s*:\w+\s*\n)+)\s*\.end sparse-switch',
    re.MULTILINE,
)

_SPARSE_SWITCH_CASE_RE = re.compile(
    r'0x([0-9a-fA-F]+)\s*->\s*:(\w+)'
)

_LABEL_RE = re.compile(r'(?m)^:(\w+)\b')


def _build_smali_from_method(m) -> str:
    """
    androguard EncodedMethod -> ê°„ë‹¨í•œ smali-like í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    (instruction.get_output() ë¼ì¸ì„ ê·¸ëƒ¥ ì´ì–´ ë¶™ì´ëŠ” ì •ë„)
    """
    try:
        # newer androguard ì—ì„œëŠ” get_source()ê°€ ìˆì„ ìˆ˜ë„ ìˆìŒ
        if hasattr(m, "get_source"):
            src = m.get_source()
            if src:
                return src
    except Exception:
        pass

    code = m.get_code()
    if not code:
        return ""

    lines = []
    for ins in code.get_bc().get_instructions():
        try:
            lines.append(ins.get_output())
        except Exception:
            continue
    return "\n".join(lines)


def _parse_sparse_switch_table(smali: str) -> Dict[str, int]:
    """
    :sswitch_data_xx ë¸”ëŸ­ì—ì„œ
    ë¼ë²¨(:sswitch_yy) â†’ storage_id(int) ë§¤í•‘ì„ ë½‘ëŠ”ë‹¤.
    """
    m = _SPARSE_SWITCH_TABLE_RE.search(smali)
    if not m:
        return {}

    body = m.group(2)
    label_to_id: Dict[str, int] = {}
    for line in body.splitlines():
        m2 = _SPARSE_SWITCH_CASE_RE.search(line)
        if not m2:
            continue
        val_hex, label = m2.groups()
        try:
            storage_id = int(val_hex, 16)
        except ValueError:
            continue
        label_to_id[label] = storage_id
    return label_to_id


def _extract_meta_ids_from_method_smali(smali: str, logger: "DualLogger") -> Dict[int, Dict[str, str]]:
    """
    í•˜ë‚˜ì˜ ë©”ì„œë“œ smali í…ìŠ¤íŠ¸ ì•ˆì—ì„œ
    - sparse-switch í…Œì´ë¸”
    - ê° ë¶„ê¸° ë¸”ë¡ ì•ˆì˜ getFilesDir / getCacheDir / getDir + const-string
    ë¥¼ ì´ìš©í•´

      storage_id(int) â†’ { base, subdir }

    ë¥¼ ë½‘ì•„ë‚¸ë‹¤.
    base: "files" / "cache" / "dir" ë“±
    subdir: "app_analytics", "browser_proc" ê°™ì€ ì„œë¸Œ ë””ë ‰í„°ë¦¬ ì´ë¦„
    """
    label_to_id = _parse_sparse_switch_table(smali)
    if not label_to_id:
        return {}

    # ë¼ë²¨ ìœ„ì¹˜ ì¸ë±ìŠ¤ë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ì„œ case ë¸”ëŸ­ ë²”ìœ„ë¥¼ ì¡ëŠ”ë‹¤
    label_positions: Dict[str, int] = {}
    for m in _LABEL_RE.finditer(smali):
        label = m.group(1)
        label_positions[label] = m.start()

    result: Dict[int, Dict[str, str]] = {}

    for label, storage_id in label_to_id.items():
        if label not in label_positions:
            continue

        start = label_positions[label]
        # ë‹¤ìŒ ë¼ë²¨ì´ ë‚˜ì˜¤ëŠ” ì§€ì ê¹Œì§€ë¥¼ case ë¸”ëŸ­ìœ¼ë¡œ ë³¸ë‹¤
        next_pos_candidates = [pos for lab, pos in label_positions.items() if pos > start]
        end = min(next_pos_candidates) if next_pos_candidates else len(smali)

        block = smali[start:end]

        base: Optional[str] = None
        if "getFilesDir()Ljava/io/File;" in block:
            base = "files"
        elif "getCacheDir()Ljava/io/File;" in block:
            base = "cache"
        elif "getDir(Ljava/lang/String;I)Ljava/io/File;" in block:
            base = "dir"

        # const-string "xxx" í•œ ê°œë§Œ ë‹¨ìˆœíˆ ì¡ëŠ”ë‹¤
        m_str = re.search(r'const-string [vp0-9, ]+,"([^"]+)"', block)
        subdir = m_str.group(1) if m_str else ""

        if not base and not subdir:
            # ì´ case ë¸”ëŸ­ì—ì„œëŠ” ìš°ë¦¬ê°€ ì›í•˜ëŠ” íŒ¨í„´ì´ ì•„ë‹ ìˆ˜ë„ ìˆìœ¼ë‹ˆ skip
            continue

        result[storage_id] = {
            "base": base or "",
            "subdir": subdir,
        }

    return result


# ========== sanity check (ì¶”ê°€) ==========
def sanity_check_dx(dx, logger):
    code_cnt = 0
    samples = []
    for ma in dx.get_methods():
        try:
            m = ma.get_method()
            if m.get_code() is not None:
                code_cnt += 1
                if len(samples) < 5:
                    samples.append(f"{m.get_class_name()}->{m.get_name()}{m.get_descriptor()}")
        except Exception:
            pass
    logger.log(f"[DEBUG] dx sanity: methods_with_code={code_cnt}, sample={samples[:3]}")

# ========== smali íŒŒì‹± ìœ í‹¸ ==========
def out(i):
    try:
        return i.get_output()
    except Exception:
        return ""

def opname(i):
    return i.get_name()

def _expand_range_regs(reg_expr: str) -> List[str]:
    reg_expr = reg_expr.strip()
    if ".." not in reg_expr:
        return [reg_expr] if (reg_expr.startswith("v") or reg_expr.startswith("p")) and reg_expr[1:].isdigit() else []
    a, b = [t.strip() for t in reg_expr.split("..")]
    if not (a and b and a[0] in "vp" and b[0] in "vp" and a[0] == b[0]):
        return []
    pfx = a[0]
    sa = int(a[1:]); sb = int(b[1:])
    return [f"{pfx}{k}" for k in range(sa, sb+1)]

def parse_invoke_callee(i) -> Optional[str]:
    s = out(i)
    parts = [p.strip() for p in s.split(",")]
    for p in reversed(parts):
        if p.startswith("L") and "->" in p and "(" in p and ")" in p:
            return p
    return None

def parse_invoke_args(i) -> List[str]:
    s = out(i); regs = []
    l = s.find("{"); r = s.find("}")
    if l != -1 and r != -1 and r > l+1:
        body = s[l+1:r].strip()
        for p in body.split(","):
            p = p.strip()
            if ".." in p:
                regs.extend(_expand_range_regs(p))
            elif (p.startswith("v") or p.startswith("p")) and p[1:].isdigit():
                regs.append(p)
    else:
        for t in s.split(","):
            t = t.strip()
            if (t.startswith("v") or t.startswith("p")) and t[1:].isdigit():
                regs.append(t)
            elif t.startswith("L") and "->" in t:
                break
    return regs

def parse_const_string(i):
    s = out(i)
    if not s:
        return None, None
    try:
        r, lit = s.split(",", 1)
        r = r.strip()
        lit = lit.strip()
        # ë”°ì˜´í‘œ ì œê±°
        lit = _dequote(lit)
        lit = _sanitize_str_for_json(lit)
        return r, lit
    except Exception:
        return None, None

def parse_field_access(i) -> Tuple[Optional[str], Optional[str]]:
    s = out(i)
    parts = [p.strip() for p in s.split(",")]
    reg_part, field_sig = None, None
    for p in reversed(parts):
        if "->" in p and ":" in p and p.startswith("L"):
            field_sig = p
            break
    if not field_sig:
        return None, None
    reg_part = parts[0] if parts else None
    if reg_part and (reg_part[0] in "vp") and reg_part[1:].isdigit():
        return reg_part, field_sig
    return None, None

def get_field_type(field_sig: str) -> Optional[str]:
    if not field_sig or ":" not in field_sig:
        return None
    return field_sig.split(":")[-1].strip()

def meth_sig(m) -> str:
    try:
        return f"{m.get_class_name()}->{m.get_name()}{m.get_descriptor()}"
    except Exception:
        return "<unknown>"

# ========== dyn methods ==========
def load_dyn_methods(path: str):
    exact_map: Dict[str, str] = {}
    regex_map: List[Tuple[re.Pattern, str]] = []
    if not path:
        return exact_map, regex_map
    try:
        with open(path, "r", encoding="utf-8") as f:
            for ln, raw in enumerate(f, 1):
                s = raw.strip().replace("\ufeff","").replace("\u200b","")
                if not s or s.startswith("#"):
                    continue
                parts = s.split(None, 1)
                if len(parts) != 2:
                    continue
                api_sig, placeholder = parts[0], parts[1].strip()
                if api_sig.startswith("re:"):
                    try:
                        regex_map.append((re.compile(api_sig[3:].strip()), placeholder))
                    except re.error as e:
                        print(f"[WARN] dyn_methods:{ln} bad regex: {e}")
                else:
                    exact_map[norm_sig(api_sig)] = placeholder
    except FileNotFoundError:
        print(f"[WARN] dyn_methods not found: {path}")
    return exact_map, regex_map

def get_dyn_placeholder(sig: str,
                        exact_map: Dict[str,str],
                        regex_map: List[Tuple[re.Pattern,str]]) -> Optional[str]:
    if not sig:
        return None
    ns = norm_sig(sig)
    if ns in exact_map:
        return exact_map[ns]
    for r, ph in regex_map:
        if r.search(sig):
            return ph
    return None

# ========== source / sink ==========
def load_patterns(path: str):
    exact, regex = set(), []
    with open(path, "r", encoding="utf-8") as f:
        for ln, raw in enumerate(f, 1):
            s = raw.strip().replace("\ufeff","").replace("\u200b","")
            if not s or s.startswith("#"):
                continue
            if s.startswith("re:"):
                regex.append(re.compile(s[3:].strip()))
            else:
                exact.add(norm_sig(s))
    return exact, regex

def matches(sig: str, exact: set, regex: List[re.Pattern]) -> bool:
    ns = norm_sig(sig)
    if ns in exact:
        return True
    return any(r.search(sig) for r in regex)

# ========== "ì§„ì§œ ì™¸ë¶€ì¸ì§€" íŒì • ==========
def is_real_external(ma) -> bool:
    try:
        m = ma.get_method()
        code = m.get_code()
        if code:
            return False
        return bool(ma.is_external())
    except Exception:
        try:
            return bool(ma.is_external())
        except Exception:
            return False

# ========== Androguard í˜¸í™˜ í—¬í¼ ==========
def _get_vm_class(cls_analysis):
    # í‘œì¤€: ClassAnalysis -> get_vm_class()
    if hasattr(cls_analysis, "get_vm_class"):
        return cls_analysis.get_vm_class()
    # ì¼ë¶€ ì˜¤ë˜ëœ í¬í¬: get_class()ë§Œ ì¡´ì¬
    if hasattr(cls_analysis, "get_class"):
        return cls_analysis.get_class()
    return None

# ========== í•„ë“œ ì´ˆê¸°í™” ==========
def preindex_fields(dx, package: str) -> Dict[str, Dict[str, Any]]:
    field_obj: Dict[str, Dict[str, Any]] = {}
    try:
        for cls_analysis in dx.get_classes():
            cls = _get_vm_class(cls_analysis)
            if not cls:
                continue
            class_name = cls.get_name()

            for field in cls.get_fields():
                field_name = field.get_name()
                field_sig = f"{class_name}->{field_name}:{field.get_descriptor()}"
                init_value = field.get_init_value()
                if init_value and isinstance(init_value.get_value(), str):
                    field_obj[field_sig] = {"type": "String", "value": str(init_value.get_value())}
    except Exception:
        pass

    for ma in dx.get_methods():
        try:
            if is_real_external(ma):
                continue
            m = ma.get_method()
        except Exception:
            continue

        code = m.get_code()
        if not code:
            continue
        bc = code.get_bc()
        if not bc:
            continue
        insns = list(bc.get_instructions() or [])
        if not insns:
            continue

        reg_str: Dict[str,str] = {}
        reg_dir: Dict[str,str] = {}
        pending_invoke = None
        for ins in insns:
            op = opname(ins)
            if op in CONST_STRING_OPS:
                r, lit = parse_const_string(ins)
                if r and lit is not None:
                    reg_str[r] = lit
                continue
            if op in MOVE_OPS:
                toks = [t.strip() for t in out(ins).split(",")]
                if len(toks) >= 2:
                    dst, src = toks[0], toks[1]
                    if src in reg_str:
                        reg_str[dst] = reg_str[src]
                    if src in reg_dir:
                        reg_dir[dst] = reg_dir[src]
                continue
            if op in INVOKE_OPS:
                callee = parse_invoke_callee(ins)
                pending_invoke = norm_sig(callee) if callee else None
                continue
            if op in MOVE_RESULT_OPS and pending_invoke:
                dst = out(ins).strip()
                if re.search(r"->getCacheDir\(\)Ljava/io/File;$", pending_invoke or ""):
                    reg_dir[dst] = f"/data/user/0/{package}/cache"
                elif re.search(r"->getFilesDir\(\)Ljava/io/File;$", pending_invoke or ""):
                    reg_dir[dst] = f"/data/user/0/{package}/files"
                elif re.search(r"->getExternalCacheDir\(\)Ljava/io/File;$", pending_invoke or ""):
                    reg_dir[dst] = f"/storage/emulated/0/Android/data/{package}/cache"
                pending_invoke = None
                continue
            if op in (IPUT_OPS | SPUT_OPS):
                src_reg, f_sig = parse_field_access(ins)
                if src_reg and f_sig:
                    if src_reg in reg_str:
                        field_obj[f_sig] = {"type":"String","value":reg_str[src_reg]}
                    elif src_reg in reg_dir:
                        field_obj[f_sig] = {"type":"Dir","abs":reg_dir[src_reg]}
                continue
            if op in SGET_OPS:
                dst_reg, f_sig = parse_field_access(ins)
                if dst_reg and f_sig and f_sig in field_obj:
                    val = field_obj[f_sig]
                    if val.get("type") == "Dir" and val.get("abs"):
                        reg_dir[dst_reg] = val["abs"]
                    elif val.get("type") == "String" and val.get("value") is not None:
                        reg_str[dst_reg] = val["value"]
                continue

    return field_obj

# ========== 1íŒ¨ìŠ¤: intra summaries & callgraph ==========
# ========== DataStore Lambda ì¶”ì  ê°•í™” ==========
def find_lambda_classes_for_datastore(dx, caller_sig: str) -> List[str]:
    lambda_classes = []
    try:
        if "->" not in caller_sig:
            return []
        class_part = caller_sig.split("->")[0]
        for cls_analysis in dx.get_classes():
            cls = _get_vm_class(cls_analysis)
            if not cls:
                continue
            cls_name = cls.get_name()
            if cls_name.startswith(class_part):
                if ("$lambda$" in cls_name or 
                    "$special$inlined$" in cls_name or
                    "$ExternalSyntheticLambda" in cls_name or
                    "$Lambda$" in cls_name):
                    lambda_classes.append(cls_name)
    except Exception as e:
        logger.log(f"[WARN] find_lambda_classes_for_datastore error: {e}")
    return lambda_classes

def scan_lambda_for_datastore_file(dx, lambda_class: str, package: str) -> Optional[Tuple[str, str]]:
    try:
        for ma in dx.get_methods():
            try:
                m = ma.get_method()
                if m.get_class_name() != lambda_class:
                    continue
                code = m.get_code()
                if not code:
                    continue
                bc = code.get_bc()
                if not bc:
                    continue
                insns = list(bc.get_instructions() or [])
                if not insns:
                    continue
                for idx, ins in enumerate(insns):
                    op = opname(ins)
                    if op in INVOKE_OPS:
                        callee = parse_invoke_callee(ins)
                        if not callee:
                            continue
                        callee_n = norm_sig(callee)
                        if ("preferencesdatastorefile" in callee_n.lower() or
                            "preferencedatastorefile" in callee_n.lower()):
                            args = parse_invoke_args(ins)
                            if len(args) >= 2:
                                name_reg = args[1]
                                for back_idx in range(max(0, idx - 20), idx):
                                    back_ins = insns[back_idx]
                                    if opname(back_ins) in CONST_STRING_OPS:
                                        r, lit = parse_const_string(back_ins)
                                        if r == name_reg and lit:
                                            return ("files", lit.strip())
                            method_name = m.get_name()
                            if "preferencesDataStore" in method_name:
                                parts = method_name.split("$")
                                if len(parts) > 0:
                                    candidate = parts[0].replace("get-", "").replace("access$", "")
                                    if candidate and candidate not in ["invoke", "lambda", "special"]:
                                        return ("files", candidate)
            except Exception:
                continue
    except Exception as e:
        logger.log(f"[WARN] scan_lambda_for_datastore_file error: {e}")
    return None

def collect_intra_summaries(dx, package: str):
    from collections import defaultdict
    summaries: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
    callgraph: Dict[str, Set[str]] = defaultdict(set)

    _code_cnt = 0
    _skipped_external = 0

    for ma in dx.get_methods():
        try:
            if is_real_external(ma):
                _skipped_external += 1
                continue
            m = ma.get_method()
        except Exception:
            continue

        code = m.get_code()
        if not code:
            continue

        _code_cnt += 1

        bc = code.get_bc()
        if not bc:
            continue
        insns = list(bc.get_instructions() or [])
        if not insns:
            continue

        msig = meth_sig(m)

        # (A) joinë¥˜ í˜¸ì¶œ ìš”ì•½
        for ins in insns:
            op = opname(ins)
            if op in INVOKE_OPS:
                callee = parse_invoke_callee(ins)
                if not callee:
                    continue
                callee_n = norm_sig(callee)
                callgraph[msig].add(callee_n)
                if any(p in callee_n for p in JOIN_METHOD_PATTERNS):
                    summaries[msig].append({"kind":"rel_join","callee":callee_n})

        # (B) return File(base,"literal") ìš”ì•½
        base_kind, lit = scan_return_file_from_base_literal(m, package)
        if base_kind and (lit is not None):
            summaries[msig].append({
                "kind":"return_file_from_base_literal",
                "base": base_kind,
                "child": lit,
            })
        
        # (C) DataStore Lambda íŠ¹ë³„ ì²˜ë¦¬
        class_name = m.get_class_name()
        if ("datastore" in msig.lower() or 
            "datastore" in class_name.lower() or
            "$lambda$" in class_name or
            "$special$inlined$" in class_name):
            lambda_classes = find_lambda_classes_for_datastore(dx, msig)
            for lc in lambda_classes:
                result = scan_lambda_for_datastore_file(dx, lc, package)
                if result:
                    base_kind, child_name = result
                    summaries[msig].append({
                        "kind": "return_file_from_base_literal",
                        "base": base_kind,
                        "child": child_name,
                    })
                    logger.log(f"[DEBUG] Found DataStore from Lambda {lc}: {child_name}")

    logger.log(f"[DEBUG] summaries pass: methods_with_code={_code_cnt}, skipped_as_external={_skipped_external}")
    return summaries, callgraph

# ========== 1.5íŒ¨ìŠ¤: callerâ†’callee ì¸ì ë°”ì¸ë”© ìˆ˜ì§‘ ==========
def collect_param_bindings(dx,
                           package: str,
                           field_obj: Dict[str, Dict[str, Any]],
                           dyn_exact: Dict[str, str],
                           dyn_regex: List[Tuple[re.Pattern, str]],
                           max_insns: int = 12000) -> Dict[str, Dict[int, List[Dict[str,str]]]]:
    """
    â˜…  íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ë¥¸ ë©”ì„œë“œë¡œ ë„˜ê¸¸ ë•Œ, ì´ë¯¸ ë°”ì¸ë”©ëœ ê°’ë„ í•¨ê»˜ ì „ë‹¬
    """
    from collections import defaultdict

    param_bindings: Dict[str, Dict[int, List[Dict[str, str]]]] = defaultdict(lambda: defaultdict(list))

    for ma in dx.get_methods():
        try:
            if is_real_external(ma):
                continue
            m = ma.get_method()
        except Exception:
            continue

        msig = meth_sig(m)
        code = m.get_code()
        if not code:
            continue
        bc = code.get_bc()
        if not bc:
            continue
        insns = list(bc.get_instructions() or [])
        if not insns:
            continue

        reg_obj: Dict[str, Dict[str, Any]] = {}
        pending_invoke = None

        pending_join_result: Optional[Dict[str, Any]] = None
        pending_join_valid_until = -1

        sb_acc: Dict[str, str] = {}

        for idx, ins in enumerate(insns):
            if idx > max_insns:
                break

            if pending_join_result is not None and idx > pending_join_valid_until:
                pending_join_result = None
                pending_join_valid_until = -1

            op = opname(ins)
            s  = out(ins)

            if op in CONST_STRING_OPS:
                r, lit = parse_const_string(ins)
                if r and lit is not None:
                    reg_obj[r] = {"type":"String","value":lit}
                continue

            if op in IGET_OPS or op in SGET_OPS:
                dst_reg, field_sig = parse_field_access(ins)
                if dst_reg and field_sig and field_sig in field_obj:
                    reg_obj[dst_reg] = field_obj[field_sig].copy()
                continue

            if op in MOVE_OPS:
                toks = [t.strip() for t in s.split(",")]
                if len(toks) >= 2:
                    dst, src = toks[0], toks[1]
                    if src in reg_obj:
                        reg_obj[dst] = reg_obj[src].copy()
                    if src in sb_acc:
                        sb_acc[dst] = sb_acc[src]
                continue

            if op in INVOKE_OPS:
                callee = parse_invoke_callee(ins)
                callee_n = norm_sig(callee) if callee else None
                args = parse_invoke_args(ins)
                pending_invoke = (callee_n, args)

                # StringBuilder.append
                if callee_n and any(pat in callee_n for pat in STRINGBUILDER_PATTERNS):
                    if len(args) >= 2:
                        sb_reg = args[0]
                        app_reg = args[1]
                        append_val = ""
                        if app_reg in reg_obj:
                            append_val = reg_obj[app_reg].get("abs") or reg_obj[app_reg].get("value") or ""
                        if sb_reg not in sb_acc:
                            sb_acc[sb_reg] = ""
                        sb_acc[sb_reg] += str(append_val)

                # join â†’ move-result ì§í›„ parent/child í•©ì¹˜ê¸° ì¤€ë¹„
                if callee_n and any(p in callee_n for p in JOIN_METHOD_PATTERNS):
                    if len(args) >= 2:
                        parent_reg = args[0]
                        child_reg  = args[1]
                        parent_abs = (reg_obj.get(parent_reg, {}) or {}).get("abs") or ""
                        child_val  = (reg_obj.get(child_reg, {})  or {}).get("value") or ""
                        if parent_abs and child_val:
                            joined = f"{parent_abs.rstrip('/')}/{child_val.lstrip('/')}"
                            pending_join_result = {"type":"Dir","abs":joined}
                            pending_join_valid_until = idx + 3
                        else:
                            pending_join_result = None
                            pending_join_valid_until = -1
                    else:
                        pending_join_result = None
                        pending_join_valid_until = -1

                # ì¸ì ìŠ¤ëƒ…ìƒ· ì €ì¥ : íŒŒë¼ë¯¸í„° ì¬ì „íŒŒ
                if callee_n:
                    for i_arg, r in enumerate(args):
                        # 1) ë ˆì§€ìŠ¤í„°ì— ì‹¤ì œ ê°ì²´ê°€ ìˆìœ¼ë©´ ìº¡ì²˜
                        pushed = False
                        if r in reg_obj and len(param_bindings[callee_n][i_arg]) < 5:
                            param_bindings[callee_n][i_arg].append(reg_obj[r].copy())
                            pushed = True

                        # 2) â˜… rì´ íŒŒë¼ë¯¸í„°(p0, p1, ...)ì´ê³ , 
                        #    í˜„ì¬ ë©”ì„œë“œ(msig)ì— ì´ë¯¸ ë°”ì¸ë”©ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ calleeë¡œ ì „ë‹¬
                        if (not pushed) and r.startswith("p") and r[1:].isdigit():
                            pidx = int(r[1:])
                            if msig in param_bindings and pidx in param_bindings[msig]:
                                for bound_obj in param_bindings[msig][pidx]:
                                    if len(param_bindings[callee_n][i_arg]) < 5:
                                        param_bindings[callee_n][i_arg].append(bound_obj.copy())

                continue

            if op in MOVE_RESULT_OPS and pending_invoke:
                dst = s.strip()
                callee_n, args = pending_invoke

                # toString()
                if callee_n and any(pat in callee_n for pat in STRINGBUILDER_TOSTRING_PATTERNS):
                    if args and args[0] in sb_acc:
                        acc = sb_acc[args[0]]
                        if acc:
                            reg_obj[dst] = {"type":"String","value":acc}
                        sb_acc.pop(args[0], None)
                    pending_invoke = None
                    continue

                # join ì§í›„
                if pending_join_result is not None:
                    reg_obj[dst] = pending_join_result.copy()
                    upper = min(idx + 10, len(insns))
                    for j in range(idx + 1, upper):
                        ins2 = insns[j]
                        if opname(ins2) in INVOKE_OPS:
                            c2 = parse_invoke_callee(ins2)
                            c2n = norm_sig(c2) if c2 else None
                            a2 = parse_invoke_args(ins2)
                            if c2n:
                                for i_arg, r in enumerate(a2):
                                    if r == dst and len(param_bindings[c2n][i_arg]) < 5:
                                        param_bindings[c2n][i_arg].append(reg_obj[dst].copy())
                            break
                    pending_join_result = None
                    pending_join_valid_until = -1
                    pending_invoke = None
                    continue

                # dyn placeholder / BASE_DIR_RULES
                if callee_n:
                    ph = get_dyn_placeholder(callee_n, dyn_exact, dyn_regex)
                    if ph:
                        reg_obj[dst] = {"type":"Placeholder","value":ph}
                    for rx, maker in BASE_DIR_RULES:
                        if rx.match(callee_n):
                            try:
                                abs_path = maker(package, args, reg_obj)
                                if abs_path:
                                    reg_obj[dst] = {"type":"Dir","abs":abs_path}
                            except Exception:
                                pass
                            break

                    upper = min(idx + 10, len(insns))
                    if dst in reg_obj:
                        for j in range(idx + 1, upper):
                            ins2 = insns[j]
                            if opname(ins2) in INVOKE_OPS:
                                c2 = parse_invoke_callee(ins2)
                                c2n = norm_sig(c2) if c2 else None
                                a2 = parse_invoke_args(ins2)
                                if c2n:
                                    for i_arg, r in enumerate(a2):
                                        if r == dst and len(param_bindings[c2n][i_arg]) < 5:
                                            param_bindings[c2n][i_arg].append(reg_obj[dst].copy())
                                break

                pending_invoke = None
                continue

    logger.log(f"[INFO] param bindings collected: {len(param_bindings)} methods")
    return param_bindings

# ========== callee ë‚´ë¶€ return ìš”ì•½ ìŠ¤ìºë„ˆ ==========
def scan_return_file_from_base_literal(m, package: str):
    try:
        code = m.get_code()
        if not code:
            return None, None
        bc = code.get_bc()
        insns = list(bc.get_instructions() or [])
        if not insns:
            return None, None
    except Exception:
        return None, None

    reg_base_kind: Dict[str, str] = {}
    reg_string: Dict[str, str] = {}
    sb_acc: Dict[str, str] = {}

    pending_new_instance: Optional[str] = None
    ctor_candidate_reg: Optional[str] = None
    ctor_literal: Optional[str] = None
    ctor_base_kind: Optional[str] = None

    last_invoke_callee: Optional[str] = None
    last_invoke_args: List[str] = []

    def _op(i):
        try: return i.get_name()
        except: return ""
    def _out(i):
        try: return i.get_output()
        except: return ""
    def _callee(i) -> Optional[str]:
        s = _out(i)
        parts = [p.strip() for p in s.split(",")]
        for p in reversed(parts):
            if p.startswith("L") and "->" in p and "(" in p and ")" in p:
                return p
        return None
    def _args(i) -> List[str]:
        s = _out(i); regs=[]
        l=s.find("{"); r=s.find("}")
        if l!=-1 and r!=-1 and r>l+1:
            body=s[l+1:r].strip()
            for p in body.split(","):
                p=p.strip()
                if ".." in p:
                    a,b=[t.strip() for t in p.split("..")]
                    if a and b and a[0]==b[0] and a[0] in "vp" and a[1:].isdigit() and b[1:].isdigit():
                        sa,sb=int(a[1:]),int(b[1:])
                        regs.extend([f"{a[0]}{k}" for k in range(sa,sb+1)])
                elif (p.startswith("v") or p.startswith("p")) and p[1:].isdigit():
                    regs.append(p)
        else:
            for t in s.split(","):
                t=t.strip()
                if (t.startswith("v") or t.startswith("p")) and t[1:].isdigit(): regs.append(t)
                elif t.startswith("L") and "->" in t: break
        return regs

    def _apply_base_rules(callee_sig_norm: str, args: List[str]) -> Optional[str]:
        if not callee_sig_norm: return None
        ns = callee_sig_norm
        for rx, maker in BASE_DIR_RULES:
            if rx.match(ns):
                try:
                    return maker(package, args, {})
                except Exception:
                    pass
        low = ns.lower()
        if "getcachedir" in low or "getcachedirectory" in low:
            return f"/data/user/0/{package}/cache"
        if "getfilesdir" in low:
            return f"/data/user/0/{package}/files"
        return None

    FILE_CTOR_FILE_STRING = norm_sig("Ljava/io/File;-><init>(Ljava/io/File;Ljava/lang/String;)V")
    SB_APPEND = norm_sig("Ljava/lang/StringBuilder;->append(")
    SB_TOSTR  = norm_sig("Ljava/lang/StringBuilder;->toString()")
    SB2_APPEND = norm_sig("Ljava/lang/StringBuffer;->append(")
    SB2_TOSTR  = norm_sig("Ljava/lang/StringBuffer;->toString()")

    for ins in insns:
        op = _op(ins)
        s  = _out(ins)

        # ----- const-string / const-string/jumbo -----
        if op in ("const-string","const-string/jumbo"):
            try:
                r, lit = s.split(",", 1)
                r = r.strip()
                lit = _dequote(lit.strip())
                reg_string[r] = lit
            except:
                pass
            continue

        # ----- move* -----
        if op.startswith("move"):
            toks = [t.strip() for t in s.split(",")]
            if len(toks) >= 2:
                dst, src = toks[0], toks[1]
                if src in reg_base_kind: reg_base_kind[dst] = reg_base_kind[src]
                if src in reg_string:    reg_string[dst]    = reg_string[src]
                if src in sb_acc:        sb_acc[dst]        = sb_acc[src]
            continue

        # ----- new-instance File -----
        if op == "new-instance" and "Ljava/io/File;" in s:
            try:
                r = s.split(",")[0].strip()
                pending_new_instance = r
            except:
                pending_new_instance = None
            continue

        # ----- invoke* -----
        if op.startswith("invoke"):
            callee_raw = _callee(ins)
            callee = norm_sig(callee_raw or "")
            last_invoke_callee = callee
            last_invoke_args   = _args(ins)

            # StringBuilder.append / StringBuffer.append
            if callee.startswith(SB_APPEND) or callee.startswith(SB2_APPEND):
                if len(last_invoke_args) >= 2:
                    sb, arg = last_invoke_args[0], last_invoke_args[1]
                    val = reg_string.get(arg, "")
                    sb_acc[sb] = sb_acc.get(sb, "") + val
                continue

            # File(File base, String name) ctor
            if callee == FILE_CTOR_FILE_STRING:
                if len(last_invoke_args) >= 3:
                    this_reg, base_reg, name_reg = last_invoke_args[0], last_invoke_args[1], last_invoke_args[2]
                    if pending_new_instance and this_reg == pending_new_instance:
                        ctor_candidate_reg = this_reg
                        if name_reg in reg_string:
                            ctor_literal = reg_string[name_reg]
                        elif name_reg in sb_acc and sb_acc[name_reg]:
                            ctor_literal = sb_acc[name_reg]
                        else:
                            ctor_literal = None
                        ctor_base_kind = reg_base_kind.get(base_reg)
            continue

        # ----- move-result* -----
        if op in ("move-result-object","move-result"):
            dst = s.strip()
            if last_invoke_callee:
                abs_path = _apply_base_rules(last_invoke_callee, last_invoke_args)
                if abs_path:
                    if "/cache" in abs_path:
                        reg_base_kind[dst] = "cache"
                    elif "/files" in abs_path:
                        reg_base_kind[dst] = "files"
            continue

        # ----- return-object -----
        if op.startswith("return-object"):
            toks = [t.strip() for t in s.split(",")]
            ret_reg = toks[-1] if toks else None
            if ctor_candidate_reg and ret_reg == ctor_candidate_reg:
                base_kind = ctor_base_kind
                if not base_kind:
                    window = 40
                    idx_ret = insns.index(ins)
                    start = max(0, idx_ret - window)
                    for j in range(idx_ret - 1, start - 1, -1):
                        sj = _out(insns[j]).lower()
                        if "getcachedir" in sj or "getcachedirectory" in sj:
                            base_kind = "cache"; break
                        if "getfilesdir" in sj:
                            base_kind = "files"; break
                if not base_kind:
                    base_kind = "files"
                if ctor_literal is not None:
                    return base_kind, ctor_literal
                return None, None

        # ----- ë³´ì¡°: DataStore ì¼€ì´ìŠ¤(ëŒë‹¤ ìš”ì•½ íŒíŠ¸) -----
        method_name = m.get_name() if hasattr(m, 'get_name') else ""
        class_name = m.get_class_name() if hasattr(m, 'get_class_name') else ""
        if "datastore" in class_name.lower() or "lambda" in class_name.lower():
            for ins2 in insns:
                if _op(ins2).startswith("invoke"):
                    callee_raw = _callee(ins2)
                    if callee_raw and "preferencesDataStoreFile" in callee_raw:
                        for j in range(insns.index(ins2), min(len(insns), insns.index(ins2)+5)):
                            if _op(insns[j]) == "move-result-object":
                                for k in range(max(0, insns.index(ins2)-10), insns.index(ins2)):
                                    if _op(insns[k]) == "const-string":
                                        try:
                                            r2, lit2 = _out(insns[k]).split(",", 1)
                                            lit2 = _dequote(lit2.strip())
                                            return "files", lit2.rstrip(".preferences_pb")
                                        except:
                                            pass

    return None, None

# ========== 2íŒ¨ìŠ¤: ìš”ì•½ 10í™‰ ==========
def propagate_summaries(summaries: Dict[str, List[Dict[str, Any]]],
                        callgraph: Dict[str, Set[str]],
                        max_hops: int = 10):
    expanded = {m: list(vs) for m, vs in summaries.items()}
    hop_count = 0
    while hop_count < max_hops:
        changed = False
        for m, callees in callgraph.items():
            for cal in callees:
                if cal in expanded:
                    for item in expanded[cal]:
                        if item not in expanded.setdefault(m, []):
                            expanded[m].append(item)
                            changed = True
        if not changed:
            break
        hop_count += 1
    return expanded

# ========== í—¬í¼: ë””ë ‰í„°ë¦¬ ë² ì´ìŠ¤ ì¶”ì • ==========
def guess_base_dir_for_name(pkg: str, name: str) -> str:
    low = (name or "").lower()
    if "cache" in low or "tmp" in low or "thumbnail" in low:
        return f"/data/user/0/{pkg}/cache/{name}"
    return f"/data/user/0/{pkg}/files/{name}"

# ========== 3íŒ¨ìŠ¤: ì‹¤ì œ taint + origin ==========
def track_with_interproc(dx,
                         package: str,
                         src_matcher,
                         sink_matcher,
                         inter_summaries: Dict[str, List[Dict[str, Any]]],
                         field_obj: Dict[str, Dict[str, Any]],
                         dyn_exact: Dict[str,str],
                         dyn_regex: List[Tuple[re.Pattern,str]],
                         param_bindings: Dict[str, Dict[int, List[Dict[str,str]]]],
                         max_insns: int,
                         want_full_trace: bool,
                         mem_log_path: str = "memory_trace.log",
                         output_jsonl: str = None):  # ğŸ‘ˆ ì¶”ê°€!
    # all_flows = []  # ğŸ‘ˆ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œê±°!
    flow_count = 0  # flow ê°œìˆ˜ë§Œ ì¹´ìš´íŠ¸

    #  ë©”ëª¨ë¦¬ ë¡œê·¸ ì´ˆê¸°í™” (ì¶”ê°€)
    method_counter = 0
    proc = psutil.Process(os.getpid())
    mem_log_dir = os.path.dirname(mem_log_path)
    if mem_log_dir:
        os.makedirs(mem_log_dir, exist_ok=True)

    mem_log_file = open(mem_log_path, "w", encoding="utf-8")
    mem_log_file.write(f"[MEMORY TRACE START] {datetime.now()}\n")
    mem_log_file.write("method_count,memory_mb,last_method\n")
    mem_log_file.flush()
    
    print(f"[INFO] Memory log will be saved to: {mem_log_path}")
    
    # ===== JSONL íŒŒì¼ ì´ˆê¸°í™” (ì‹¤ì‹œê°„ ì €ì¥ìš©) =====
    jsonl_file = None
    if output_jsonl:
        jsonl_dir = os.path.dirname(output_jsonl)
        if jsonl_dir:
            os.makedirs(jsonl_dir, exist_ok=True)
        jsonl_file = open(output_jsonl, "w", encoding="utf-8")
        print(f"[INFO] Flows will be saved to: {output_jsonl}")
    else:
        print(f"[WARN] No output_jsonl specified, flows will not be saved!")


    # ===== ê±°ëŒ€ ë©”ì„œë“œ í•„í„° ì„¤ì • (ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€) =====
    SKIP_LARGE_METHODS = True
    MAX_INSTRUCTIONS = 300
    skipped_count = 0
    print(f"[INFO] Large method filter: {'ENABLED' if SKIP_LARGE_METHODS else 'DISABLED'} (threshold: {MAX_INSTRUCTIONS} instructions)")

    def log_mem_to_file(count, last_sig):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ íŒŒì¼ì— ê¸°ë¡"""
        try:
            mem_mb = proc.memory_info().rss / (1024 * 1024)
            # ì½˜ì†” ì¶œë ¥
            print(f"[MEM] after {count} methods: {mem_mb:.1f} MB | last: {last_sig[:80]}")
            # íŒŒì¼ ê¸°ë¡
            mem_log_file.write(f"{count},{mem_mb:.1f},{last_sig[:80]}\n")
            mem_log_file.flush()
        except Exception as e:
            print(f"[MEM] logging failed: {e}")


    for ma in dx.get_methods():
        try:
            if is_real_external(ma):
                continue
            m = ma.get_method()
        except Exception:
            continue
        msig = meth_sig(m)

        #  ë©”ì„œë“œ ì¹´ìš´í„° ì¦ê°€ ë° ì£¼ê¸°ì  ë¡œê·¸
        method_counter += 1
        if method_counter % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸
            log_mem_to_file(method_counter, msig)

        code = m.get_code()
        if not code:
            continue
        bc = code.get_bc()
        if not bc:
            continue
        insns = list(bc.get_instructions() or [])
        if not insns:
            continue
        
        # ===== ê±°ëŒ€ ë©”ì„œë“œ ìŠ¤í‚µ (ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€) =====
        if SKIP_LARGE_METHODS:
            insn_count = len(insns)
            if insn_count > MAX_INSTRUCTIONS:
                skipped_count += 1
                # ì²˜ìŒ 10ê°œ + 100ê°œë§ˆë‹¤ ë¡œê·¸
                if skipped_count <= 10 or skipped_count % 100 == 0:
                    print(f"[SKIP] Large method ({insn_count} insns): {msig}")
                # ë©”ëª¨ë¦¬ ë¡œê·¸ì—ë„ ê¸°ë¡
                if method_counter % 100 == 0:
                    log_mem_to_file(method_counter, f"[SKIPPED-{insn_count}] {msig}")
                continue  # ìŠ¤í‚µ!

        reg_taint = defaultdict(bool)
        reg_src_idx = defaultdict(lambda: -1)
        reg_src_api = defaultdict(str)
        reg_obj: Dict[str, Dict[str, Any]] = {}
        reg_origin: Dict[str, Optional[int]] = {}

        trace_struct: List[Dict[str, Any]] = []
        trace_invoke: List[Tuple[int, str]] = []
        pending_invoke: Optional[Tuple] = None
        pending_join_result = None
        pending_join_valid_until = -1

        def add_struct(idx, op, **kw):
            if want_full_trace:
                ent = {"idx": idx, "op": op}
                ent.update(kw)
                trace_struct.append(ent)

        # íŒŒë¼ë¯¸í„° ì˜¤ë¦¬ì§„ ì´ˆê¸° ìŠ¤ìº”
        for ins in insns:
            s = out(ins)
            for tok in s.split(","):
                tok = tok.strip()
                if tok.startswith("p") and tok[1:].isdigit():
                    pidx = int(tok[1:])
                    reg_origin[tok] = pidx

        stringbuilder_accumulator: Dict[str, str] = {}

        for idx, ins in enumerate(insns):
            if idx > max_insns:
                break

            if pending_join_result is not None and idx > pending_join_valid_until:
                pending_join_result = None
                pending_join_valid_until = -1

            op = opname(ins)

            # ----- const-string -----
            if op in CONST_STRING_OPS:
                r, s0 = parse_const_string(ins)
                if r:
                    reg_obj[r] = {"type":"String","value":s0}
                    add_struct(idx, op, writes=[r], const_string=s0)
                continue

            # ----- field get -----
            if op in IGET_OPS or op in SGET_OPS:
                dst_reg, field_sig = parse_field_access(ins)
                if dst_reg and field_sig and field_sig in field_obj:
                    reg_obj[dst_reg] = field_obj[field_sig].copy()
                    add_struct(idx, op, writes=[dst_reg], field_sig=field_sig)
                else:
                    if dst_reg and field_sig:
                        field_type = get_field_type(field_sig)
                        field_lower = (field_sig + " " + (field_type or "")).lower()
                        is_file_type = field_type and ("java/io/File" in field_type or "java/nio/file/Path" in field_type or "/Path;" in field_type)
                        is_dir_name = any(kw in field_lower for kw in ["cache","cachedir","filesdir","directory","folder"])
                        if is_file_type or is_dir_name:
                            if "cache" in field_lower:
                                reg_obj[dst_reg] = {"type":"Dir","abs":f"/data/user/0/{package}/cache"}
                            elif "files" in field_lower:
                                reg_obj[dst_reg] = {"type":"Dir","abs":f"/data/user/0/{package}/files"}
                            else:
                                reg_obj[dst_reg] = {"type":"Dir","abs":f"/data/user/0/{package}/files"}
                            add_struct(idx, op, writes=[dst_reg], field_sig=field_sig)
                continue

            # ----- move* -----
            if op in MOVE_OPS:
                toks = [t.strip() for t in out(ins).split(",")]
                if len(toks) >= 2:
                    dst, src = toks[0], toks[1]
                    reg_taint[dst] = reg_taint.get(src, False)
                    reg_src_idx[dst] = reg_src_idx.get(src, -1)
                    reg_src_api[dst] = reg_src_api.get(src, "")
                    if src in reg_obj:
                        reg_obj[dst] = reg_obj[src].copy()
                    if src in reg_origin:
                        reg_origin[dst] = reg_origin[src]
                    if src in stringbuilder_accumulator:
                        stringbuilder_accumulator[dst] = stringbuilder_accumulator[src]
                    add_struct(idx, op, reads=[src], writes=[dst])
                continue

            # ----- invoke* -----
            if op in INVOKE_OPS:
                callee = parse_invoke_callee(ins)
                callee_n = norm_sig(callee) if callee else None
                
                args = parse_invoke_args(ins)  # í•œ ë²ˆë§Œ íŒŒì‹±
                
                # âœ… ë””ë²„ê¹… ì½”ë“œ - reg_obj ì§ì ‘ ì‚¬ìš©
                if callee_n and re.match(r"^LX/[^;]+;->A0[0-9]", callee_n):
                    print(f"[TAINT-A0X] {callee_n}")
                    print(f"  args: {args}")
                    for i_arg, r in enumerate(args):
                        snap = reg_obj.get(r)
                        if snap:
                            print(f"  arg[{i_arg}] ({r}): {snap}")
                
                # ì›ë˜ ì½”ë“œ ê³„ì†
                is_source = bool(callee_n and src_matcher(callee_n))
                is_sink   = bool(callee_n and sink_matcher(callee_n))
                # DataStore ë˜í¼ note íƒœê¹…
                note = None
                if callee_n and any(rx.search(callee_n) for rx in DS_WRAPPER_RES):
                    note = "datastore-wrapper"

                # 1) DataStore ì „ìš© íŒíŠ¸ ê³„ì‚° (ìš”ì•½ ê¸°ë°˜)
                ds_hint = None
                if callee_n:
                    low = callee_n.lower()
                    if re.search(r'/datastore/.+;->create\(', low) and 'kotlin/jvm/functions/function0' in low:
                        produce_reg = args[-1] if args else None
                        lam_cls = None
                        if produce_reg and produce_reg in reg_obj:
                            lam_cls = reg_obj[produce_reg].get("class")
                        if not lam_cls and want_full_trace:
                            for t in reversed(trace_struct[-30:]):
                                c = (t.get("from_callee") or t.get("callee") or "")
                                if "$ExternalSyntheticLambda" in c or "Lambda$" in c:
                                    lam_cls = c.split(";->")[0]
                                    break
                        if lam_cls:
                            for meth, vs in inter_summaries.items():
                                if meth.startswith(lam_cls):
                                    for summ in vs:
                                        if summ.get("kind") == "return_file_from_base_literal":
                                            base  = summ.get("base") or "files"
                                            child = summ.get("child") or ""
                                            root  = f"/data/user/0/{package}/{'cache' if base=='cache' else 'files'}"
                                            abs_hint = f"{root.rstrip('/')}/{str(child).lstrip('/')}" if child else root
                                            ds_hint = {"type":"Dir","abs":abs_hint}
                                            break
                                if ds_hint: break

                # 2) ctor ë°”ì¸ë”©
                if callee_n and "-><init>(" in callee_n and len(args) >= 1:
                    this_reg = args[0]
                    if this_reg not in reg_obj:
                        reg_obj[this_reg] = {"type":"Instance","class": callee_n.split(";->")[0]}
                    for i in range(1, len(args)):
                        src_r = args[i]
                        if src_r in reg_obj:
                            reg_obj[this_reg][f"ctor_arg{i}"] = reg_obj[src_r].copy()
                    for i_arg, r in enumerate(args):
                        if r in reg_obj and len(param_bindings[callee_n][i_arg]) < 5:
                            param_bindings[callee_n][i_arg].append(reg_obj[r].copy())

                # 3) ì¸ì ìŠ¤ëƒ…ìƒ·
                arg_objs_snapshot = []
                arg_literals_snapshot = {}
                for i_arg, r in enumerate(args):
                    snap = reg_obj.get(r)
                    arg_objs_snapshot.append(snap.copy() if isinstance(snap, dict) else snap)
                    if isinstance(snap, dict):
                        if snap.get("abs"):
                            arg_literals_snapshot[i_arg] = {"abs": snap["abs"]}
                        elif snap.get("value"):
                            arg_literals_snapshot[i_arg] = {"value": snap["value"]}

                add_struct(idx, op,
                           reads=args, callee=callee_n,
                           is_src=is_source, is_sink=is_sink,
                           arg_objs_snapshot=arg_objs_snapshot,
                           arg_literals_snapshot=arg_literals_snapshot,
                           note=note)

                if callee_n:
                    trace_invoke.append((idx, callee_n))

                # 4) StringBuilder.append
                if callee_n and any(p in callee_n for p in STRINGBUILDER_PATTERNS):
                    if len(args) >= 2:
                        sb_reg = args[0]
                        app_reg = args[1]
                        app_val = ""
                        if app_reg in reg_obj:
                            app_val = reg_obj[app_reg].get("abs") or reg_obj[app_reg].get("value") or ""
                        if sb_reg not in stringbuilder_accumulator:
                            stringbuilder_accumulator[sb_reg] = ""
                        stringbuilder_accumulator[sb_reg] += str(app_val)

                # 5) File ìƒì„±ì ë° join ê°ì§€ 
                is_file_constructor = (callee_n == "Ljava/io/File;-><init>(Ljava/io/File;Ljava/lang/String;)V")
                is_other_join = bool(callee_n and any(p in callee_n for p in JOIN_METHOD_PATTERNS))

                if is_file_constructor or is_other_join:
                    # File(File parent, String child)ì˜ ê²½ìš° args[1]=parent, args[2]=child (args[0]ì€ this)
                    if is_file_constructor and len(args) >= 3:
                        this_reg   = args[0]  # âœ… ì¶”ê°€!
                        parent_reg = args[1]
                        child_reg  = args[2]
                    # ë‹¤ë¥¸ join ë©”ì„œë“œ: args[0] = parent, args[1] = child
                    elif is_other_join and len(args) >= 2:
                        this_reg   = None     # âœ… ì¶”ê°€!
                        parent_reg = args[0]
                        child_reg  = args[1]
                    else:
                        pending_join_result = None
                        pending_join_valid_until = -1
                        continue

                    parent_obj = reg_obj.get(parent_reg, {})
                    child_obj  = reg_obj.get(child_reg, {})
                    parent_abs = parent_obj.get("abs", "")

                    # child_valì´ ì—†ìœ¼ë©´ ë ˆì§€ìŠ¤í„° ì´ë¦„ì„ Placeholderë¡œ
                    child_val  = child_obj.get("value", "")
                    if not child_val:
                        child_val = f"<{child_reg}>"

                    if parent_abs and child_val:
                        # ê²½ë¡œ ê²°í•©
                        new_abs = f"{parent_abs.rstrip('/')}/{child_val.lstrip('/')}"
                        if is_file_constructor and this_reg is not None:
                            #  ê¸°ì¡´ì—ëŠ” move-result ë•Œê¹Œì§€ ë¯¸ë£¨ê³  ìˆì—ˆìŒ
                            #  ìƒì„±ìëŠ” move-resultê°€ ì—†ìœ¼ë‹ˆ ì—¬ê¸°ì„œ ë°”ë¡œ this_reg ë„£ì–´ì¤Œ.
                            reg_obj[this_reg] = {"type": "Dir", "abs": new_abs}
                            add_struct(
                                idx,
                                op,
                                reads=[parent_reg, child_reg],
                                writes=[this_reg],
                                note="file-ctor-join",
                                obj=reg_obj[this_reg],
                            )

                            # ë°”ë¡œ ë‹¤ìŒ invokeì—ì„œ ì¸ìë¡œ ì“°ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ param_bindingsì—ë„ ì£¼ì…
                            upper = min(idx + 5, len(insns))
                            for future_idx in range(idx + 1, upper):
                                future_ins = insns[future_idx]
                                if opname(future_ins) in INVOKE_OPS:
                                    fcallee = parse_invoke_callee(future_ins)
                                    fcallee_n = norm_sig(fcallee) if fcallee else None
                                    fargs = parse_invoke_args(future_ins)
                                    if fcallee_n:
                                        for f_i_arg, f_r in enumerate(fargs):
                                            if f_r == this_reg and len(param_bindings[fcallee_n][f_i_arg]) < 5:
                                                param_bindings[fcallee_n][f_i_arg].append(
                                                    reg_obj[this_reg].copy()
                                                )
                                    break
                            # ìƒì„±ìëŠ” move-resultë¥¼ ì•ˆ ì“°ë‹ˆê¹Œ pending_joinì€ í•„ìš” ì—†ìŒ
                            pending_join_result = None
                            pending_join_valid_until = -1
                        else:
                            # join ê³„ì—´ (Uri.resolve ë“±)ì€ ê¸°ì¡´ì²˜ëŸ¼ move-resultì— ì ìš©
                            pending_join_result = {"type": "File", "abs": new_abs}
                            pending_join_valid_until = idx + 1
                    else:
                        pending_join_result = None
                        pending_join_valid_until = -1
                else:
                    pending_join_result = None
                    pending_join_valid_until = -1

                # 6) sink ì²˜ë¦¬
                is_dir_sink = False
                if callee_n:
                    is_dir_sink = any(p in callee_n for p in DIR_LIKE_SINK_PATTERNS)

                if callee_n and (is_sink or is_dir_sink or any(callee_n.startswith(p) for p in ALWAYS_CREATION_SINK_PREFIXES)):
                    tainted_now = any(reg_taint.get(r, False) for r in args)
                    start_idx = idx
                    srcs = set()
                    for r in args:
                        if reg_taint.get(r, False):
                            if reg_src_idx[r] >= 0:
                                start_idx = min(start_idx, reg_src_idx[r])
                            if reg_src_api[r]:
                                srcs.add(reg_src_api[r])
                    source_label = " | ".join(sorted(srcs)) if srcs else "<NO_TAINT>"
                    taint_path = [c for (i, c) in trace_invoke if start_idx <= i <= idx] or ["<none>"]

                    sink_args_objs = []
                    for i_arg, r in enumerate(args):
                        obj_here = reg_obj.get(r)
                        if (not obj_here) and r in reg_origin:
                            pidx = reg_origin[r]
                            if msig in param_bindings and pidx in param_bindings[msig] and param_bindings[msig][pidx]:
                                obj_here = param_bindings[msig][pidx].copy()[0]
                                obj_here["type"] = obj_here.get("type","Unknown") + "|FromCaller"
                        elif (not obj_here) and r.startswith("p") and r[1:].isdigit():
                            pidx = int(r[1:])
                            if msig in param_bindings and pidx in param_bindings[msig] and param_bindings[msig][pidx]:
                                obj_here = param_bindings[msig][pidx].copy()[0]
                                obj_here["type"] = obj_here.get("type","Unknown") + "|FromCaller"
                        sink_args_objs.append({
                            "arg_index": i_arg,
                            "reg": r,
                            "obj": obj_here or {"type":"Unknown","value":f"<{r}>"},
                        })

                    flow = {
                        "package": package,
                        "caller": msig,
                        "source": source_label,
                        "sink": callee_n,
                        "invoke_offset": idx,
                        "tainted": tainted_now,
                        "taint_path": taint_path,
                        "sink_args": sink_args_objs,
                    }
                    if want_full_trace:
                        flow["trace_slice"] = list(trace_struct)
                    
                    # ===== ì‹¤ì‹œê°„ íŒŒì¼ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½) =====
                    if jsonl_file:
                        jsonl_file.write(json.dumps(flow, ensure_ascii=False) + "\n")
                        jsonl_file.flush()  
                    flow_count += 1

                # 7) interproc ìš”ì•½ (rel_join)
                if callee_n and callee_n in inter_summaries:
                    for summ in inter_summaries[callee_n]:
                        if summ.get("kind") == "rel_join":
                            forced = {
                                "package": package,
                                "caller": msig,
                                "source": "<INTERPROC>",
                                "sink": callee_n,
                                "invoke_offset": idx,
                                "tainted": False,
                                "taint_path": ["<interproc>"],
                                "sink_args": [
                                    {
                                        "arg_index": i_arg,
                                        "reg": r,
                                        "obj": reg_obj.get(r, {"type":"Unknown","value":f"<{r}>"}),
                                    }
                                    for i_arg, r in enumerate(args)
                                ],
                                "forced_artifact": None,
                            }
                            if want_full_trace:
                                forced["trace_slice"] = list(trace_struct)
                            
                            # ===== ì‹¤ì‹œê°„ íŒŒì¼ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½) =====
                            if jsonl_file:
                                jsonl_file.write(json.dumps(forced, ensure_ascii=False) + "\n")
                                jsonl_file.flush()  
                            flow_count += 1

                # 8) ë‹¤ìŒ move-resultìš© pending_invokeëŠ” í•­ìƒ 5-íŠœí”Œ
                pending_invoke = (callee_n, args, is_source, idx, ds_hint)
                continue

            # ----- move-result* -----
            if op in MOVE_RESULT_OPS and pending_invoke:
                dst = out(ins).strip()
                callee_n, args, is_source, inv_idx, hint = pending_invoke

                if hint and isinstance(hint, dict) and "abs" in hint:
                    reg_obj[dst] = hint.copy()
                    add_struct(idx, op, writes=[dst], from_callee=callee_n, note="datastore-hint")

                # ì¸ìŠ¤í„´ìŠ¤ getter + ctor_arg ë°”ì¸ë”© ë³µì›
                if (
                    callee_n
                    and not callee_n.startswith("Landroid/")
                    and "->get" in callee_n
                    and callee_n.endswith(")Ljava/io/File;")
                    and len(args) == 1
                ):
                    this_reg = args[0]
                    if this_reg in reg_obj:
                        this_obj = reg_obj[this_reg]
                        for key, val in this_obj.items():
                            if key.startswith("ctor_arg") and isinstance(val, dict) and val.get("type") == "String":
                                child_name = val.get("value", "")
                                base_dir = None
                                for k2, v2 in this_obj.items():
                                    if k2.startswith("ctor_arg") and isinstance(v2, dict) and v2.get("type") == "Dir":
                                        base_dir = v2.get("abs", "")
                                        break
                                if not base_dir:
                                    if "cache" in (callee_n or "").lower():
                                        base_dir = f"/data/user/0/{package}/cache"
                                    else:
                                        base_dir = f"/data/user/0/{package}/files"
                                if child_name:
                                    full_path = f"{base_dir.rstrip('/')}/{child_name.lstrip('/')}"
                                    reg_obj[dst] = {"type":"Dir","abs":full_path}
                                    add_struct(idx, op, writes=[dst], from_callee=callee_n,
                                               note="instance-method-with-ctor-args")
                                    upper = min(idx + 10, len(insns))
                                    for future_idx in range(idx + 1, upper):
                                        future_ins = insns[future_idx]
                                        if opname(future_ins) in INVOKE_OPS:
                                            fcallee = parse_invoke_callee(future_ins)
                                            fcallee_n = norm_sig(fcallee) if fcallee else None
                                            fargs = parse_invoke_args(future_ins)
                                            if fcallee_n:
                                                for f_i_arg, f_r in enumerate(fargs):
                                                    if f_r == dst and len(param_bindings[fcallee_n][f_i_arg]) < 5:
                                                        param_bindings[fcallee_n][f_i_arg].append(reg_obj[dst].copy())
                                            break
                                    pending_invoke = None
                                    # continue
                                break

                # ë¬´ì¸ì File ë¦¬í„´ ì²˜ë¦¬
                if (
                    callee_n
                    and callee_n.endswith(")Ljava/io/File;")
                    and (len(args) == 0 or (len(args) == 1 and args[0].startswith("p")))
                ):
                    if callee_n in param_bindings and 0 in param_bindings[callee_n]:
                        for b in param_bindings[callee_n][0]:
                            if b.get("type") == "Dir" and b.get("abs"):
                                reg_obj[dst] = {"type":"Dir","abs":b["abs"]}
                                add_struct(idx, op, writes=[dst], from_callee=callee_n, note="noarg-file:dir-from-this")
                                pending_invoke = None
                                upper = min(idx + 10, len(insns))
                                for future_idx in range(idx + 1, upper):
                                    future_ins = insns[future_idx]
                                    if opname(future_ins) in INVOKE_OPS:
                                        fcallee = parse_invoke_callee(future_ins)
                                        fcallee_n = norm_sig(fcallee) if fcallee else None
                                        fargs = parse_invoke_args(future_ins)
                                        if fcallee_n:
                                            for f_i_arg, f_r in enumerate(fargs):
                                                if f_r == dst and len(param_bindings[fcallee_n][f_i_arg]) < 5:
                                                    param_bindings[fcallee_n][f_i_arg].append(reg_obj[dst].copy())
                                        break
                                # continue
                            if b.get("type") == "String" and b.get("value"):
                                guessed = guess_base_dir_for_name(package, b["value"])
                                reg_obj[dst] = {"type":"Dir","abs":guessed}
                                add_struct(idx, op, writes=[dst], from_callee=callee_n, note="noarg-file:string-from-this")
                                pending_invoke = None
                                upper = min(idx + 10, len(insns))
                                for future_idx in range(idx + 1, upper):
                                    future_ins = insns[future_idx]
                                    if opname(future_ins) in INVOKE_OPS:
                                        fcallee = parse_invoke_callee(future_ins)
                                        fcallee_n = norm_sig(fcallee) if fcallee else None
                                        fargs = parse_invoke_args(future_ins)
                                        if fcallee_n:
                                            for f_i_arg, f_r in enumerate(fargs):
                                                if f_r == dst and len(param_bindings[fcallee_n][f_i_arg]) < 5:
                                                    param_bindings[fcallee_n][f_i_arg].append(reg_obj[dst].copy())
                                        break

                # StringBuilder.toString()
                if callee_n and any(p in callee_n for p in STRINGBUILDER_TOSTRING_PATTERNS):
                    if args and args[0] in stringbuilder_accumulator:
                        accumulated = stringbuilder_accumulator[args[0]]
                        if accumulated:
                            reg_obj[dst] = {"type":"String","value":accumulated}
                        del stringbuilder_accumulator[args[0]]
                    add_struct(idx, op, writes=[dst], from_callee=callee_n, obj=reg_obj.get(dst))
                    pending_invoke = None

                # join ê²°ê³¼ ì ìš©
                if pending_join_result is not None:
                    reg_obj[dst] = pending_join_result.copy()
                    pending_join_result = None
                    pending_join_valid_until = -1
                else:
                    ph = get_dyn_placeholder(callee_n or "", dyn_exact, dyn_regex)
                    if ph:
                        reg_obj[dst] = {"type":"Placeholder","value":ph}
                    if is_source:
                        reg_taint[dst] = True
                        reg_src_idx[dst] = inv_idx
                        reg_src_api[dst] = callee_n or "<source>"

                # BASE_DIR_RULES ì ìš©
                if callee_n:
                    # [FIX] Android API (getFilesDir, getCacheDir ë“±)ëŠ” í•­ìƒ ë®ì–´ì“°ê¸°
                    # ë‹¤ë¥¸ ê²½ë¡œ ê³„ì‚°ì€ ì´ë¯¸ ê³„ì‚°ëœ ê²½ìš° ìŠ¤í‚µ
                    is_android_dir_api = any(pattern in callee_n for pattern in [
                        'getFilesDir()', 'getCacheDir()', 'getExternalFilesDir()',
                        'getExternalCacheDir()', 'getDataDir()', 'getCodeCacheDir()'
                    ])

                    if is_android_dir_api or dst not in reg_obj:
                        for rx, maker in BASE_DIR_RULES:
                            if rx.match(callee_n):
                                try:
                                    abs_path = maker(package, args, reg_obj)
                                    if abs_path:
                                        reg_obj[dst] = {"type":"Dir","abs":abs_path}
                                except Exception:
                                    pass
                                break

                # return-summary ì ìš©
                if callee_n and callee_n in inter_summaries:
                    for summ in inter_summaries[callee_n]:
                        if summ.get("kind") == "return_file_from_base_literal":
                            base = summ.get("base")
                            child = summ.get("child") or ""
                            if base == "cache":
                                abs_path = f"/data/user/0/{package}/cache"
                            else:
                                abs_path = f"/data/user/0/{package}/files"
                            if child:
                                abs_path = f"{abs_path.rstrip('/')}/{str(child).lstrip('/')}"
                            reg_obj[dst] = {"type":"Dir","abs":abs_path}
                            add_struct(idx, op, writes=[dst], from_callee=callee_n, note="return-summary(base+literal)")
                            upper2 = min(idx + 10, len(insns))
                            for future_idx in range(idx + 1, upper2):
                                future_ins = insns[future_idx]
                                if opname(future_ins) in INVOKE_OPS:
                                    fcallee = parse_invoke_callee(future_ins)
                                    fcallee_n = norm_sig(fcallee) if fcallee else None
                                    fargs = parse_invoke_args(future_ins)
                                    if fcallee_n:
                                        for f_i_arg, f_r in enumerate(fargs):
                                            if f_r == dst and len(param_bindings[fcallee_n][f_i_arg]) < 5:
                                                param_bindings[fcallee_n][f_i_arg].append(reg_obj[dst].copy())
                                    break

                add_struct(idx, op, writes=[dst], from_callee=callee_n, obj=reg_obj.get(dst))

                # look-ahead: ë‹¤ìŒ í˜¸ì¶œ ì¸ì ìŠ¤ëƒ…ìƒ· ì£¼ì…
                total_insns = len(insns)
                upper = min(idx + 10, total_insns)
                if dst in reg_obj:
                    for future_idx in range(idx + 1, upper):
                        future_ins = insns[future_idx]
                        future_op = opname(future_ins)
                        if future_op in INVOKE_OPS:
                            future_callee = parse_invoke_callee(future_ins)
                            future_callee_n = norm_sig(future_callee) if future_callee else None
                            future_args = parse_invoke_args(future_ins)
                            if future_callee_n:
                                for f_i_arg, f_r in enumerate(future_args):
                                    if f_r == dst:
                                        if len(param_bindings[future_callee_n][f_i_arg]) < 5:
                                            param_bindings[future_callee_n][f_i_arg].append(reg_obj[dst].copy())
                            break

                pending_invoke = None
                continue

    # ===== ë©”ëª¨ë¦¬ ë¡œê·¸ ì¢…ë£Œ =====
    try:
        mem_log_file.write(f"[MEMORY TRACE END] {datetime.now()}\n")
        mem_log_file.write(f"Total methods processed: {method_counter}\n")
        if SKIP_LARGE_METHODS:
            mem_log_file.write(f"Skipped large methods: {skipped_count}\n")
            print(f"[INFO] Skipped {skipped_count} large methods ({skipped_count/method_counter*100:.2f}%)")
        mem_log_file.close()
        print(f"[INFO] Memory trace saved to: {mem_log_path}")
    except Exception as e:
        print(f"[WARN] Failed to close memory log: {e}")

    # ===== JSONL íŒŒì¼ ì¢…ë£Œ =====
    if jsonl_file:
        try:
            jsonl_file.close()
            print(f"[OK] flows written: {output_jsonl} (rows={flow_count})")
        except Exception as e:
            print(f"[WARN] Failed to close JSONL file: {e}")
    
    return flow_count 
    

def integrate_meta_storage_extraction(dx, package_name: str, output_dir: str) -> Dict[int, str]:
    """
    Meta ì•± ìë™ ì¶”ì¶œ í†µí•© í•¨ìˆ˜ (1203 ë©”ì¸ì—ì„œ ì“°ë˜ ê²ƒ ê·¸ëŒ€ë¡œ)
    """


    # ===== ê°•ì œ ë¡œê¹… ì‹œì‘ =====
    import sys
    
    sys.stderr.write("\n" + "="*80 + "\n")
    sys.stderr.write("[META-EXTRACTION] ì‹œì‘!\n")
    sys.stderr.write(f"[META-EXTRACTION] íŒ¨í‚¤ì§€: {package_name}\n")
    sys.stderr.write(f"[META-EXTRACTION] dx ê°ì²´: {type(dx)}\n")
    sys.stderr.write("="*80 + "\n\n")
    sys.stderr.flush()

    print("\n" + "="*80)
    print("[META-EXTRACTION] ì‹œì‘!")
    print(f"[META-EXTRACTION] íŒ¨í‚¤ì§€: {package_name}")
    print(f"[META-EXTRACTION] ì¶œë ¥ ë””ë ‰í„°ë¦¬: {output_dir}")
    print("="*80 + "\n")

    # ===== í•µì‹¬: extract í•¨ìˆ˜ í˜¸ì¶œ ì „ ë¡œê·¸ =====
    sys.stderr.write("[META-EXTRACTION] extract_meta_storage_ids_from_dex() í˜¸ì¶œ ì‹œì‘...\n")
    sys.stderr.flush()
    print("[META-EXTRACTION] extract_meta_storage_ids_from_dex() í˜¸ì¶œ ì‹œì‘...")
    
    mapping = extract_meta_storage_ids_from_dex(dx)
    
    sys.stderr.write(f"[META-EXTRACTION] extract í˜¸ì¶œ ì™„ë£Œ: {len(mapping)}ê°œ\n")
    sys.stderr.flush()
    print(f"[META-EXTRACTION] ì¶”ì¶œ ê²°ê³¼: {len(mapping)}ê°œ")
    
    if not mapping:
        print("[META-ID] âŒ ì¶”ì¶œ ì‹¤íŒ¨")
        
        # ëŒ€ì²´ ë¶„ì„
        print("[META-FALLBACK] ë©”ì„œë“œ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
        analyze_context_file_methods(dx)
        
        # ===== ë°”ì´íŠ¸ì½”ë“œ ìƒì„¸ ë¤í”„ =====
        print("\n[META-DEEP] ë°”ì´íŠ¸ì½”ë“œ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
        
        # Facebook (ì •ì‹ ë²„ì „) - ì˜ˆìƒ íƒ€ê²Ÿ
        if "facebook.katana" in package_name or package_name == "com.facebook.katana":
            # 40ê°œ ì¤‘ì—ì„œ ê°€ì¥ ë³µì¡í•œ ë©”ì„œë“œ ì„ íƒ (instructions ë§ì€ ê²ƒ)
            # ë¡œê·¸ì—ì„œ LX/002 ê°™ì€ í›„ë³´ê°€ ë³´ì˜€ìœ¼ë¯€ë¡œ ì¼ë‹¨ ìŠ¤í‚µ
            print("[INFO] Facebook ì •ì‹ ë²„ì „ - íƒ€ê²Ÿ ë©”ì„œë“œ ë¯¸í™•ì • (LX/002 ë“± í›„ë³´ ìˆìŒ)")
        
        # Instagram (ì •ì‹ ë²„ì „) - ì˜ˆìƒ íƒ€ê²Ÿ
        elif "instagram.android" in package_name or package_name == "com.instagram.android":
            # 44ê°œ ì¤‘ì—ì„œ ë³µì¡í•œ ê²ƒ (LX/0zq, LX/0zv ë“±)
            print("[INFO] Instagram ì •ì‹ ë²„ì „ - íƒ€ê²Ÿ ë©”ì„œë“œ ë¯¸í™•ì •")
        
        # Threads
        elif "barcelona" in package_name or package_name == "com.instagram.barcelona":
            # ê³¼ê±° ì„±ê³µ ì‚¬ë¡€ (LX/191) - ì´ê±´ ì°¾ì•„ì•¼ í•¨
            print("[INFO] Threads - LX/191 ê²€ìƒ‰ ì‹œë„...")
            dump_method_bytecode_detail(dx, "LX/191;->A00(Landroid/content/Context;I)Ljava/io/File;")
        
        # Facebook Lite
        elif "facebook.lite" in package_name or package_name == "com.facebook.lite":
            print("[INFO] Facebook Lite - LX/0Ah ë¶„ì„...")
            dump_method_bytecode_detail(dx, "LX/0Ah;->A00(Landroid/content/Context;I)Ljava/io/File;")
        
        # Instagram Lite
        elif "instagram.lite" in package_name or package_name == "com.instagram.lite":
            print("[INFO] Instagram Lite - LX/0AH ë¶„ì„...")
            dump_method_bytecode_detail(dx, "LX/0AH;->A00(Landroid/content/Context;I)Ljava/io/File;")
        
        else:
            print(f"[WARN] ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í‚¤ì§€: {package_name}")
        
        return {}


    result_ids: Dict[str, Dict[str, str]] = {}

    for sid, dir_name in mapping.items():
        # base íƒ€ì… ê²°ì •
        if dir_name.startswith("cache/"):
            base = "cache"
            subdir = dir_name[6:]
        elif dir_name.startswith("files/"):
            base = "files"
            subdir = dir_name[6:]
        elif dir_name.startswith("app_"):
            base = "files"
            subdir = dir_name
        else:
            base = "files"
            subdir = dir_name

        result_ids[str(sid)] = {"base": base, "subdir": subdir}

    output = {
        "package": package_name,
        "ids": result_ids,
    }

    os.makedirs(output_dir, exist_ok=True)
    json_path = os.path.join(output_dir, "meta_storage_ids.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    print(f"[META-ID] âœ“ JSON ì €ì¥: {json_path}")
    return mapping


# ========== main ==========
def main():
    ap = argparse.ArgumentParser(
        description="10-hop interprocedural taint with caller value + origin + resolve() tracking "
                    "[MERGED: taint_ip + param-repropagation + memory trace]"
    )
    ap.add_argument("--apk", required=True)
    ap.add_argument("--sources", required=True)
    ap.add_argument("--sinks", required=True)
    ap.add_argument("--out", required=True)
    ap.add_argument("--dyn-methods", default=None)
    ap.add_argument("--max-insns", type=int, default=12000)
    ap.add_argument("--full-trace", action="store_true")
    ap.add_argument("--debug", action="store_true")
    ap.add_argument("--mem-log", default="memory_trace.log")  # â˜… ë©”ëª¨ë¦¬ ë²„ì „ì—ì„œ ì´ë¯¸ ìˆë˜ ì˜µì…˜
    args = ap.parse_args()

    global logger
    logger = DualLogger(args.debug)

    src_exact, src_rx = load_patterns(args.sources)
    sink_exact, sink_rx = load_patterns(args.sinks)
    src_matcher = lambda s: matches(s, src_exact, src_rx)
    sink_matcher = lambda s: matches(s, sink_exact, sink_rx)

    dyn_exact, dyn_regex = load_dyn_methods(args.dyn_methods)

    a, dx = load_with_fallback(args.apk)
    sanity_check_dx(dx, logger)
    package_name = a.get_package() or "<pkg>"
    logger.log(f"[INFO] package = {package_name}")



    # Meta storage debug JSON (debug_and_extract_meta_storage_ids)
    # try:
    #     meta_json_path = Path(args.out).with_name("meta_storage_ids_debug.json")
    #     debug_and_extract_meta_storage_ids(dx, logger, str(meta_json_path))
    # except Exception as e:
    #     logger.log(f"[META-Debug] debug_and_extract_meta_storage_ids ì‹¤íŒ¨: {e!r}")

    # Meta storage config ìë™ ì¶”ì¶œ (integrate_meta_storage_extraction)
    try:
        out_path = Path(args.out)
        output_dir = str(out_path.parent)

        # âœ… stderrë¡œ ê°•ì œ ì¶œë ¥ (subprocess íŒŒì´í”„ë¥¼ ìš°íšŒ)
        sys.stderr.write("\n" + "âš™ï¸"*40 + "\n")
        sys.stderr.write("[MAIN] Meta Storage ì¶”ì¶œ ì‹œì‘!\n")
        sys.stderr.write("âš™ï¸"*40 + "\n\n")
        sys.stderr.flush()

        print("\n" + "âš™ï¸"*40)  # âœ… ì¶”ê°€!
        print("[MAIN] Meta Storage ì¶”ì¶œ ì‹œì‘!")  # âœ… ì¶”ê°€!
        print("âš™ï¸"*40 + "\n")  # âœ… ì¶”ê°€!

        meta_storage_ids = integrate_meta_storage_extraction(
            dx=dx,
            package_name=package_name,
            output_dir=output_dir,
        )
        
        sys.stderr.write(f"[MAIN] âœ“ ì¶”ì¶œ ì™„ë£Œ: {len(meta_storage_ids)}ê°œ\n")
        sys.stderr.flush()

        print(f"[MAIN] âœ“ ì¶”ì¶œ ì™„ë£Œ, ê²°ê³¼: {meta_storage_ids}")  # âœ… ì¶”ê°€!


        if meta_storage_ids:
            logger.log(f"[META-ID] âœ“ {len(meta_storage_ids)}ê°œ ë§¤í•‘ ì¶”ì¶œ ì„±ê³µ")
        else:
            print("[MAIN] âŒ meta_storage_idsê°€ ë¹„ì–´ìˆìŒ!")  # âœ… ì¶”ê°€!
            sys.stderr.write("[MAIN] âŒ meta_storage_idsê°€ ë¹„ì–´ìˆìŒ!\n")
            sys.stderr.flush()
    except Exception as e:
        sys.stderr.write(f"\n[ERROR] ===== Meta Storage ì˜ˆì™¸ =====\n")
        sys.stderr.write(f"[ERROR] {e}\n")
        sys.stderr.write(f"[ERROR] ==============================\n\n")
        sys.stderr.flush()
        print(f"[ERROR] ===== Meta Storage ì¶”ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ! =====")  # âœ… ê°•ì¡°!
        print(f"[ERROR] ì—ëŸ¬ ë©”ì‹œì§€: {e}")
        print(f"[ERROR] ì—ëŸ¬ íƒ€ì…: {type(e)}")
        logger.log(f"[WARN] Meta storage ID ì¶”ì¶œ ì‹¤íŒ¨: {e!r}")
        import traceback
        traceback.print_exc()
        print(f"[ERROR] ==========================================")


    logger.log("[INFO] preindex fields ...")
    field_obj = preindex_fields(dx, package_name)
    logger.log(f"[INFO] preindexed fields: {len(field_obj)}")

    logger.log("[INFO] collect intra summaries ...")
    intra_summaries, callgraph = collect_intra_summaries(dx, package_name)
    logger.log(f"[INFO] intra summaries: {len(intra_summaries)}, callgraph nodes: {len(callgraph)}")

    cnt_rs = sum(
        1 for vs in intra_summaries.values() for s in vs
        if s.get("kind") == "return_file_from_base_literal"
    )
    logger.log(f"[DEBUG] return_summary(intra) count = {cnt_rs}")

    logger.log("[INFO] collect param bindings from callers ...")
    param_bindings = collect_param_bindings(
        dx,
        package_name,
        field_obj,
        dyn_exact,
        dyn_regex,
        max_insns=args.max_insns,
    )
    logger.log(f"[INFO] param bindings collected: {len(param_bindings)} methods")

    logger.log("[INFO] propagate summaries (multi-hop) ...")
    inter_summaries = propagate_summaries(intra_summaries, callgraph)
    logger.log(f"[INFO] inter summaries: {len(inter_summaries)}")

    logger.log("[INFO] trace with interproc ...")
    flow_count = track_with_interproc(
        dx,
        package=package_name,
        src_matcher=src_matcher,
        sink_matcher=sink_matcher,
        inter_summaries=inter_summaries,
        field_obj=field_obj,
        dyn_exact=dyn_exact,
        dyn_regex=dyn_regex,
        param_bindings=param_bindings,
        max_insns=args.max_insns,
        want_full_trace=args.full_trace,
        mem_log_path=args.mem_log,  
        output_jsonl=args.out,     
    )

    logger.log(f"[OK] Total flows: {flow_count}")
    logger.close()


if __name__ == "__main__":
    main()
